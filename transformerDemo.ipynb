{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.loads data\n",
    "# 2.preprocesses data -> dataset\n",
    "# 3.tools\n",
    "# 3.1 generates position embedding\n",
    "# 3.2 create mask. (a.padding, b.decoder)\n",
    "# 3.3 scaled_dot_product_attention\n",
    "# 4. builds model\n",
    "# 4.1 MultiheadAttention\n",
    "# 4.2 EncoderLayer\n",
    "# 4.3 DecoderLayer\n",
    "# 4.4 EncoderModel\n",
    "# 4.5 DecoderModel\n",
    "# 4.6 Transformer\n",
    "# 5. optimizer & loss\n",
    "# 6.train step -> train\n",
    "# 7 Evaluate and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='ted_hrlr_translate',\n",
      "    version=1.0.0,\n",
      "    description='Data sets derived from TED talk transcripts for comparing similar language pairs\n",
      "where one is high resource and the other is low resource.',\n",
      "    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n",
      "    features=Translation({\n",
      "        'en': Text(shape=(), dtype=tf.string),\n",
      "        'pt': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    total_num_examples=54781,\n",
      "    splits={\n",
      "        'test': 1803,\n",
      "        'train': 51785,\n",
      "        'validation': 1193,\n",
      "    },\n",
      "    supervised_keys=('pt', 'en'),\n",
      "    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n",
      "      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n",
      "      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n",
      "      booktitle = {HLT-NAACL},\n",
      "      year    = {2018},\n",
      "      }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "examples,info = tfds.load('ted_hrlr_translate/pt_to_en',with_info = True,as_supervised=True)\n",
    "train_examples,val_examples = examples['train'],examples['validation']\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'e quando melhoramos a procura , tiramos a \\xc3\\xbanica vantagem da impress\\xc3\\xa3o , que \\xc3\\xa9 a serendipidade .'\n",
      "b'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .'\n",
      "\n",
      "b'mas e se estes fatores fossem ativos ?'\n",
      "b'but what if it were active ?'\n",
      "\n",
      "b'mas eles n\\xc3\\xa3o tinham a curiosidade de me testar .'\n",
      "b\"but they did n't test for curiosity .\"\n",
      "\n",
      "b'e esta rebeldia consciente \\xc3\\xa9 a raz\\xc3\\xa3o pela qual eu , como agn\\xc3\\xb3stica , posso ainda ter f\\xc3\\xa9 .'\n",
      "b'and this conscious defiance is why i , as an agnostic , can still have faith .'\n",
      "\n",
      "b\"`` `` '' podem usar tudo sobre a mesa no meu corpo . ''\"\n",
      "b'you can use everything on the table on me .'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pt,en in train_examples.take(5):\n",
    "    print(pt.numpy())\n",
    "    print(en.numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "(en.numpy() for pt,en in train_examples),target_vocab_size = 2**13)\n",
    "pt_tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "(pt.numpy() for pt,en in train_examples),target_vocab_size = 2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string is Transformer is awesome.\n",
      "7915 --> T\n",
      "1248 --> ran\n",
      "7946 --> s\n",
      "7194 --> former \n",
      "13 --> is \n",
      "2799 --> awesome\n",
      "7877 --> .\n"
     ]
    }
   ],
   "source": [
    "sample_string = \"Transformer is awesome.\"\n",
    "tokenized_string = en_tokenizer.encode(sample_string)\n",
    "print('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "origin_string = en_tokenizer.decode(tokenized_string)\n",
    "print('The original string is {}'.format(origin_string))\n",
    "\n",
    "assert origin_string == sample_string\n",
    "\n",
    "for token in tokenized_string:\n",
    "    print('{} --> {}'.format(token,en_tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 20000\n",
    "batch_size = 64\n",
    "max_length = 40\n",
    "\n",
    "def encode_to_subword(pt_sentence,en_sentence):\n",
    "    pt_sequence = [pt_tokenizer.vocab_size]+pt_tokenizer.encode(pt_sentence.numpy())+[pt_tokenizer.vocab_size + 1]\n",
    "    en_sequence = [en_tokenizer.vocab_size]+en_tokenizer.encode(en_sentence.numpy())+[en_tokenizer.vocab_size + 1]\n",
    "    return pt_sequence,en_sequence\n",
    "\n",
    "def filter_by_max_length(pt,en):\n",
    "    return tf.logical_and(tf.size(pt)<=max_length,tf.size(en)<=max_length)\n",
    "\n",
    "def tf_encode_to_subword(pt_sentence,en_sentence):\n",
    "    return tf.py_function(encode_to_subword,[pt_sentence,en_sentence],[tf.int64,tf.int64])\n",
    "\n",
    "train_dataset = train_examples.map(tf_encode_to_subword)\n",
    "train_dataset = train_dataset.filter(filter_by_max_length)\n",
    "train_dataset = train_dataset.shuffle(buffer_size).padded_batch(batch_size,padded_shapes=([-1],[-1]))\n",
    "valid_dataset = val_examples.map(tf_encode_to_subword)\n",
    "valid_dataset = valid_dataset.filter(filter_by_max_length).padded_batch(batch_size,padded_shapes=([-1],[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 38) (64, 40)\n",
      "(64, 39) (64, 35)\n",
      "(64, 39) (64, 39)\n",
      "(64, 39) (64, 39)\n",
      "(64, 39) (64, 36)\n"
     ]
    }
   ],
   "source": [
    "for pt_batch,en_batch in valid_dataset.take(5):\n",
    "    print(pt_batch.shape,en_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "# 位置编码\n",
    "# PE(pos,2i) = sin(pos/10000^(2i/d_model))\n",
    "# PE(pos,2i+1) = cos(pos/10000^(2i/d_model))\n",
    "\n",
    "# pos 词语在句中的位置\n",
    "# i 是在embedding长度中的位置\n",
    "# d_model 词向量的长度\n",
    "\n",
    "# pos.shape:[sentence_length,1] \n",
    "# i.shape: [1,d_model]\n",
    "# result.shape: [sentence_length,d_model]\n",
    "# np.newaxis  none对象 用于创建新的维度\n",
    "import numpy as np\n",
    "def get_angles(pos,i,d_model):\n",
    "    angle_rates = 1/np.power(10000,(2*(i//2))/np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def get_position_embedding(sentence_length,d_model):\n",
    "    angle_rads = get_angles(np.arange(sentence_length)[:,np.newaxis],\n",
    "                           np.arange(d_model)[np.newaxis,:],\n",
    "                           d_model)\n",
    "    # sines.shape: [sentence_length,d_model / 2]\n",
    "    # cosines.shape:[sentence_length,d_model/2]\n",
    "    sines = np.sin(angle_rads[:,0::2])\n",
    "    cosines = np.cos(angle_rads[:,1::2])\n",
    "    position_embedding = np.concatenate([sines,cosines],axis = -1)\n",
    "    # position_embedding.shape : [1,sentence_length,d_model]\n",
    "    position_embedding = position_embedding[np.newaxis,...]\n",
    "    return tf.cast(position_embedding,dtype=tf.float32)\n",
    "\n",
    "position_embedding = get_position_embedding(50,512)\n",
    "print(position_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABiP0lEQVR4nO2dd5hU1fnHP++9U3dne2dZWKqAoIiooEYFe+9RExONGjW/JMZYYktMoiYxMcY0k2iMRhO7RkWDYsNgAykCUqTXZdned/qc3x/3zuzssgsD7AIL5/M855l7z71z77nLcObMW76vKKXQaDQazYGBsbcHoNFoNJo9h570NRqN5gBCT/oajUZzAKEnfY1GozmA0JO+RqPRHEDoSV+j0WgOIPp00heR9SLyhYgsFJF5dl+uiLwjIqvs15y+HINGo9HsLUTkcRGpFpElPRwXEfmjiKwWkcUiMiHp2BX2PLlKRK7orTHtiZX+FKXUeKXURHv/duA9pdQI4D17X6PRaPZH/gmctp3jpwMj7HYt8FewFsfAT4GjgCOBn/bWAnlvmHfOBZ60t58EztsLY9BoNJo+Ryk1C6jfzinnAk8pi9lAtoiUAKcC7yil6pVSDcA7bP/LI2UcvXGR7aCAt0VEAY8opR4FipRSlfbxrUBRd28UkWuxvvlAHIfnK4O6tEzKBpXgWruaNWYao5whvCUFfL6xifElHuo31NJSNoTmhhYOKXaxcUUFWQ4D1+hRrFi7BVd6BmNK0mhauoqWSIyCPC+OQUNZXd1Ge2MjxKI4vD5yc9MZkOGGxiratjbSEogSVgqHQJpp4MlwYXpcOLMywZNBMCa0hKK0BsIEglEi4SixSIhYJIyKxaw/QzzzWQTEQAwDEQMxTcQwMQwTEUEM7FfBMARDBNMUTBEMA/vV6jfEuqQhYl02vh2/DVY/WMfsv2vH37jT37vL33+bf5AdHN9B/y6f2cNpzcEIWU5BiYERamdVC6RvWk/xYQezfHMTWTWbKDzkYJatrWRMepiWmjYCQ4ZRXVnD+JGlVC5cSlTBwFEDWdHsoL2hjoyCfEZkGjR+uY6mSIwcj4OMIQNoMtKoqG0nEgwQDfoxHC7cGT4KszzkeJxIWz3B+kaCTUHaIzHCSqGwVlQOEVyG4HIZOL1OHGluDI8bw52GcrhQhoOYgkhMEYopwtEYoWiMcEQRisaIRmOomCIWU6gYKKXsFoNYDGV/tpSyP2MqhoKOz5v92qmPHWTh9/MsfeWvq1VKFezq+43MgYpIINV7LQWST37UnudSpRTYlLS/2e7rqX+36etJ/1ilVIWIFALviMiXyQeVUsr+QtgG+w/3KICRlq8u9Pv455jTuPPPdzDoknM4N+dwnirZwCF3XYfve2/x0e0jePY7T/Lez5/inZc/4NNbyrjhuNs5NS+dQf+dyXGX/ZxBR0zh07sm8N+xpzKzpp3vnD2Owj8+xzkPz+bz114lEmilcMwxfO3SSdx94lB45QHm/va//O/LOrYGIuQ6TSZkezho6mByRpZSeNppqIOnsKbdwYcbGvjfimpWrWugvrKFlqoNBBqqCPtbiUVCqFgUAMPhwnC4cHp9ODzpuNKzcKZn4UpLx+1x4vI6cLhM3B4nbq+DNI+D7DQnPo+TDLcDn8dqXqdJmtPEEMHtMPA4DJyGte00DJymJF5NEUz7N51pf0EYkrSN9WUQ/xKJ90HHl4QhneffjnM7z8pGil8ORtdvmR7o6bR31jZy6kAXYYcX78Z5nP2ByZE//Ca3ffwxE+54m3MevpH/e28Wh15yP/+dVMkHf/uEZb9/gT/+6u98MuMe7ssbT1M4xm8f/w3Hz8xm/otPc8x11/DGKS7eOOZKpm9t5cLyPKb86x6mew/nzsfnUb1mJY3rl5BeUMbIY4/l/84cxcVjCjA/fYH1z73K6jdXs7DOz5ZAmKgClyHku0yGpDsZWJZJ0bhC8g8ZSsaokbiGH0Ist4ygr4j2cIxaf5QtLUEqmgNsbvSzucFPZaOfxpYggbYwQX+YkD9CKBghFo0RDrQTDfqJRUJEIyFrkREO2Z+1GCoWRcWixOzPnYpGE5/B+GvX7e319SfCC5/YsFsXiARwHHROqvcKJJmu+wV9at5RSlXYr9XAK1i2qSr75wv2a3VfjkGj0Wh2ChHEMFNqvUAFUJa0P9Du66l/t+mzSV9E0kUkI74NnAIsAaYBcU/0FcBrfTUGjUaj2Xkk8Yt8R60XmAZ8047imQQ02ebvGcApIpJjO3BPsft2m7407xQBr9g//x3AM0qpt0RkLvCCiFwNbAC+2odj0Gg0mp3DXun3zqXkWeAEIF9ENmNF5DgBlFJ/A6YDZwCrgXbgW/axehG5F5hrX+oepdT2HMIp02eTvlJqLXBoN/11wIk7c630vDyuGTeQ/+ZN4hsbn8f9wZMMfmAdTz9yEzW/O55Bkx3MvOVnnHzdZO5+83PGHHcEy//0a4o9DsZddDAPztlAuK2Jww4rITZvOl80BSlyOyg9bjyLavxUb2oiEmjFcLjIKipkXGkW7patVK3cRGNlK62RmDUO0yAjy01aYSbpxXk48oppc3hpDLTT0B6irjVEyB9J2FvjdtWuNlLLeWtgOF0dPxVFMBwGpsOwnLEGiCG4HAamYdh2+Y4Wt4mbYjXLsdthv4+/JtvEO2338Lfuzobe1U7fdb+n/tSduqmPJc6gn1zB2OLr+esHv+SvN/+ZaWdnUtNwKqf/dQ5P/fArvPQwXPmvBYw/82Teu+96TrjmSO6ZvoIBhx5H7J3HqAlGmZDtITL+TDb9+Wk8WQWce1gp/jn/YllzEJ/DoHBcIWrQOOYvaKS5toFAQxUA3pxisvPTKMvy4GirJVy1kfbqVpoCEdqiMaK2l8oU8JoGPoeBO9ONK9OLM92LkZaBuLwoVxqhqLJbjPZwlEAkhj8UJRSJEYrEiEYsZ24sqojZDttYrMMNlviMRbf9nCXOifZvG/2eRrD+j/YGSqnLdnBcAd/t4djjwOO9MpAk+tqRq9FoNP0LEYxeWunvi+hJX6PRaLrQW+adfRE96Ws0Gk0yvWjT3xfRk75Go9EkIQiGw7m3h9Fn9AuVzZEZitynXmXGAxfw0BV/5+pPYjxz2wnkuxzc+PCn/OTqI5he0UzJTT+nduVcfnLOwXzy9jqOKc9i8BWXM+uTjTjTs7h0YhkVb75PVTDCmEwX6UdN5eMN9TRtWQeAKz2LnCIfYwp8yNZVNK7eQk0wij8aw2UIWU6DtDwvacV5uAvziaXn0hqKUe+PUN0cJOAPEwpGOpJmwqFOzrW409ZIivONh36ZDgPDsDNxbYeuaQgO23Hrchi2U9d25sadt8lO3R48rF2duT05YuN0TczqbVJNzNoef/vPCjbPe5dXltfwxsOP8e5xX6P2yl8y57kXGPPxw1x29ggWTHuLR75+GLPr/Qz8wZ1ULJjJGScNZ+mjb5DlNJgwuZR31zXSsGEJWWWjmTokl80zF1AVjFDkdlA8cTgNrjwWbGigrXojobYmTJcXb04hI4oyKM10Y7ZU01ZRQ2tVG03hGKEkJ6vLELym4PE4cKU7cWWk48xMw0jPJObyohxuQnYmbtyJG4hYTlx/KEIoErOycO2M3FjEys5NdtzGugkU6JqYpdlJ9myc/h5Hr/Q1Go2mC/11Qk8FPelrNBpNMiK9FrK5L6InfY1Go0lC2L9X+v3Cpr/1y4185fvPYvz4m4SV4sW//IsRbz3AFbeewLqPpnF5bg25LpMn1ylc6VmckFbLkuYAh159LA0jT2TLknnkDZ/AlPIs1r27hqiCsgnFRAYfzszl1fjrtmC6vKTlDeCgwdmUZToJb/iSpg3N1ASjCfGsXJeJryid9OI8zLwSYmk5tIZi1LWHqG8LEfRHCAcjREN+W2Gzm8SsJDu+kbDxC6ZpYJj2qyGISMKG73IYCdu+Zc+3bPlxuz7EE7Q6krQSzU6RskTUOtvSk8XWdoW+svmnwv2PfI3f/eFWbr31eEoOO4lX1zZwwX3vk5Y3gOe++28OfvgvBFvqGbzgOQZ4HLxen0k05OcHXyln9sebmZTrZfQ3pvD4J+sJtzVRetBAyqWBTR9vwh9VDPc5yRo/ntUNAbZsaiLU2kAsEsKVnkVGrpcRxT7yvQ5i1Rtpraihvc5PUziasOknJ2Y50124s9w4M9Mw0zMw0jNQzjRiDnciOSsQiRG0E7PaQ1GCSYlZ0UiMWCRm2fXjNv0un60OMbVYt3+vVMXWNIAYmA5XSq0/olf6Go1Gk4zs3yt9PelrNBpNEoKO09doNJoDiv150u8XNn2HAY2blvOnxxdy8yOX4/bl8PebXsJx0+/JHDiSz797K+dOLefBZxdRPmkKlX/9rWWDv/Ranl1SRVvNJoaMK8O76kMWb2wi12VSdsIYVjcrKtY2EGprwpOVj6+ojMMGZ5Ot2mhZuYbmzc00Ryy7p89hkOVxkFbow1lQhCO/mKg3m+ZglLr2EHWtQYL+MOFAgEjI36lwShwxzITYmpi2bd/pwjCNRKUsMcSy7Sfs+Wa3YmvJdv1OAmxJYmtxuhNC6xorb0jXeP6O4inx93R3rZ1ld4unxLnRdxFnv/kLFl/xa96//wy+edwgNnzyOjfdfDFzGwL8/PMQQ449g49u/jtnTBnML1/+grzhExhU8SnLW4KMPX80rpO+ydLPKzFdXk46vJTYovdYVdGCyxAGjCvEMWYSCyqbqa9qJdTWBIA7K5/sgnSG5aaTEWsnUrnOqq7WFCRgx9yD5QPyGGKLrblwZXhwZaQhaZmINwPldBOMxBI2/fZwjGAkaomtRS2xtVjUsuUrlSS2Zn+uOrXotvb6XUXb+dFx+hqNRnNgoc07Go1Gc8AgIhjO/hmZkwp60tdoNJpktOCaRqPRHFjsz5N+v3Dk5h88gl8/cANnlGby6thr+OlPLmdLIMyFf53DpVeewYvvruOw3/2M9Z/M4HsXjmXO32dzXH4aS6SUf7+7GtPl5RtfGUL166+wyR9mpM9FzldO4KONDTRUbEHFoqQXDCKvOINxhRk4atfSsHITVS0h/FGFKZDpMEgvSie9JA8zrxgy8mkJRqltD1HTHKSlzaqaFQ36iYVD2whhdRVbMxwdVbPMeMUsh5FIzjINwZ0ssJYkvJZcKQus7XjSVjKS5JyNJ2btriO2J3q7ataOeOaBP3PfPe9wxY1/pe37lzDhzTcZdsJ53F6yhQtH5fHYY2/z628fyX9X1DL+F7ey6sNZjJ9yKGse/humCIMv/yoL/RnUrJhP1sCRnD+2hMp3PmB9e4h8l0nJxHL8uUP5ZFUtbTUbUbEohsNFWl4p5UUZDM72YDZX0r55Cy1bWqkPRRMV1lyG2GJrBl6XiTvLjSszHVdmOkZGNsrlRTnTkpy4UYKRKIGolZwVF1uLRpSdnKVsobXOYmvJJCdfJYut6apZu4ZhB1bsqPVH+sWkr9FoNHsKESuKLpWW4vVOE5EVIrJaRG7v5vhDIrLQbitFpDHpWDTp2LTeeD5t3tFoNJoumGbvrIdFxAQeBk4GNgNzRWSaUmpZ/Byl1A+Tzv8+cFjSJfxKqfG9MhgbvdLXaDSaZITeXOkfCaxWSq1VSoWA54Bzt3P+ZcCzvfAUPdIvJv1lVQEum/8XTlnwBjf++EmuD37EVRePZsErL/O7qYWEYop35SAAvjUqnVm17Yy/fAIPzlzN+gWLyCkfy5kj81n9+iL8UcWI0fkw6hjeXrqV1qr1GA4X2SVFlA/KYliOh9DqxdSvrmNrIEIopvCahiW2VpiGr7QAR0Ep0fQ8WsOW2Fp1S5CgP2IVULETs2LhHpKzkmz7VvEUh/0BsmzzYoBhdi6Y0sm2n5yUZdv2zbjdfjtia8mvcbr7x0/1A5EstrY3TJtnf/86vnXSEEy3l4efW8bxv/2EV+84gbdOvYGpL/6G+rWLODO2FJchfJ53FO11W7j3zDF89p/lTMj20H7oWfx99gba67ZQOuYgxmbDxg9W0RSOMdznomDyYaxpCLJmfSOBhioAW2zNx8GlmRSlOVDVG2nZVE1bdecCKqZYdn2fQ3Bnuq2W7cNM92GkZRBzphFzemybviW0FhdbC0asxKxQKEo0GkvY8qO24Frcnp9cQKUnsbXt2fN1ElbPWCqbvTbplwKbkvY3233b3ldkMDAEeD+p2yMi80Rktoict2tP1Blt3tFoNJpOyM5Ud8sXkXlJ+48qpR7dxRtfCryklEr+Rh6slKoQkaHA+yLyhVJqzS5eH9CTvkaj0XTGNu+kSK1SauJ2jlcAZUn7A+2+7rgU+G5yh1Kqwn5dKyIfYNn7d2vS7xfmHY1Go9mT9KJ5Zy4wQkSGiIgLa2LfJgpHREYBOcCnSX05IuK2t/OBY4BlXd+7s/SLlX6wpZH7bnyJz1pPJ9zezL8v+iVf27IQ91n3sfoH3+b8w0v4wVPzGXTkyTT+/V4ABn/n+3zywAaaN69k4sWXUVS9kFdX1JPlNBh84ig2hNNZs7qOQFMN3pwi8kszOGpYHgWOEC0rV9C0oZlmO+7a5zDIdzvwDcjAXVxMLD2PWFoOzQ1hamyxtZA/TDgYssXWwj2KrRkOpyWyliS2ZtotXhA9HqdvGoLL7Cik0lVsLR6fb9nwrfv0JLaWsOtj+w4S/bJtjP0+LrYG8KR7Bhueeo1pwTBtq1/k8VeeJT36Aq9vbmZj6zDKjjqT2df/jLMOL+Gm5xeSXT6Ww0IrebIhwLWXjuE/X9by4acbMRwujp1Qiix+my9X1mMKDD4oD9chxzFncxN1W1sItTXh8PhssbU0huelk2WECVeup3VzLa0NAdqiHTZ9r2ngMawCKi6fE3emG1dmGkZGDkZ6JhGX1yqcYsfox5s/FMUftoqoxMXWolGrKaW2FVpLUWytuwIq2zvvQEcETEfvOKqUUhER+R4wAzCBx5VSS0XkHmCeUir+BXAp8JxSSiW9fTTwiIjEsBbo9ydH/ewq/WLS12g0mj1Jb1aFU0pNB6Z36bu7y/7PunnfJ8C4XhuIjZ70NRqNJgmR/pttmwp60tdoNJou7IQjt9+hJ32NRqPpwv486feL6J2S0iKOy09j7vP/5pa7rmJRU5DT/zqH8666gGdfWMbRf7ubFe+/yf9degizH3yPY/K8LE8bxdYlHyGGyeUnDKXm1edY2RpkpM9F4Ukn8r/19dSs25wQW5swNI/xJZk4a1bTsHwDWxsDtEZiSWJrVmKWaSdmtUSEqtYQWxsDNLWGCPojRPytRIN+ol2qZnUVW+ucpCWdxNZM08DhMHA7DKtqVhfBtWSxNTPJmdvVgbuzYmu9aMLsc7E1gNu+8TjHXf0n8n75bY6fPYNBk8/ikV+/z7mDs7j3oTf5xXcm8dLszUz6/a0seecDDjnxSNY+9FsARnz7azz+3hq2Lp1P5sCRXDahlKo3Z7CmLUSB20HpMUPxFx7ER6tqaK5cTywSwp2RY4mtlWQwPC8Ns6mC9vXraam0xNb8UcvpbwqJilk+twNPjgd3dgbu7AyM9AyU0xJbi1fNag/HaA+nLrYG2zpcu4qt7QraiZuEdJPo2EPrj+iVvkaj0SQhCIajX6yHdwk96Ws0Gk0ygnbkajQazYFEb4Zs7mv0i98wBYFazlwyg4NOvpDb5BOuvXQMc557gUdPK6Y1EuMd72GoWJTvHOzj3eo2jvrWEdz/3krCbU3kDj2U80cXsOLl+fijitHjCmHcVN5YXJkQW8spHcCR5TmMzPUSWrWQ2hU124itZZT4EmJrAdNLUzCaEFsLtIcJ+sNEQ36iocAOxdZMhyshtmY4jE5ia5KUiNVVbM0VL7CyC2JrXRcuOxJb2779f++KrQFcccpQDKeLh/6+gGN+v4A3f3YypginTP8DtSvnchGW2NrCkuNpq9nEb88fy0fPfsGEbA/+ieezdsGXtNVsomzsGA7LgTVvLaMpHGN0houiYw5ndUOQlWsbEmJr3pxiMvOzOKQsm6I0B1Stp2VTNa2VrdSHYvijVk5NvHhKt2Jrvmxibh8xp4eALbZmFVCx7Pntoeh2xdbin6sdia3FdpC0pe3328cSXEut9Uf6fNgiYorI5yLyhr0/RETm2AUFnrdTkzUajWbfQHTlrN3lB8DypP1fAw8ppYYDDcDVe2AMGo1GkyKCYRoptf5In45aRAYCZwKP2fsCTAVesk95EjivL8eg0Wg0O4Ps5yv9vnbk/h74EZBh7+cBjUqpiL2/vYIC1wLXAvgwOeqhL5jz8xP5W9GhXF7xOWmXPMTSq67k0inlXP3YXIYecxo1f/gJpkDZ/93Eh/d+SXpBGcMmjqJg02yeX15HrstkyGnjWB3wsGalJbaWljeAokFZjC/OoNBop3HJUhrXNtIQtuyePodBQZqTjIFZuIuLifoKaApGaQpE2doapLo5QKAtRMjvJxxoJdZDjH6qYmtxe77LYe5YbC0RTwym0btia4n9LtfaVXpTbA2g+U/P81GWm+rqV3n81eeQmse47u5Tub9yAEOPO5dZ3/gxF04t5/tPzSdv+ATGNczn7w1+vn/VeJ5dUk3D+iWYLi+nTBoE895g+eoGTIFBYwtwHTaFTzc1UrulmWBLPQ6Pj4zCEnKL0jmowEeWBAlvWknLxhqa6rcVW/M5DLKcJu5MF55sL+5snyW25ssm4vImYvRbgh1ia62BSJ+IrcXRdvydQydn7QIichZQrZSavyvvV0o9qpSaqJSa6MXs5dFpNBpN94iwbVJkD60/0pcr/WOAc0TkDMADZAJ/ALJFxGGv9rdXUECj0Wj2Cv11Qk+FPlvpK6XuUEoNVEqVY2lFv6+U+jowE7jIPu0K4LW+GoNGo9HsLEJqq/z++sWwN5KzbgOeE5H7gM+Bf+yFMWg0Gk23iIBrP5Zh2CNPppT6QCl1lr29Vil1pFJquFLqYqVUcEfvz0lzsnT6i8w7YSpbAmFOuv9/3HTzxTz1xiomPvZ7Vv/vDX565eG8/6dZnFSSwSfRgVR9MYuB44/kOyeNYMtzz7CmLcTYTDcFp5zBO2tqqV23DhWL4isawuQR+QzOcmFuXUHd0nVsaQ4mxNZynCYZA+zErKJBxNLzaAnGqG4LsrUxQEtbiJAtthYLh4iGty+2ZtiJWVZylrGN2JrLFlvruqJwOYztiq0l053Y2vYQ6b0Pwp5a+5z7rV9Sd/FZjHjrbcad9VUe/ttc6q/8Fb978EUe/+GxvLykmokP38+yd99hytlHsewXD+IyhOHfvZ7HZ6wkGvKTUz6WyycMZPNr01nTFmKAx8mg40fRlD2Md5dV0Vy5FhWL4snKJ6fIx0Fl2QzPTcPRsInWdRtp3tRCfShKq11hzWUIHkPIchp4XSbeHA/unAzcORkYGdkolyW2FogqgpGOqllt8apZoQj+ULRbsbV4gEBX0bWuYmuxpM9eqs5b7eTtjAg4DEmp9Ue0DINGo9EkIezfNn096Ws0Gk0y0n/t9amw/xquNBqNZhewVvpGSi2l64mcJiIrbOmZ27s5fqWI1IjIQrtdk3TsChFZZbcreuP5+sWk7xoxkpOuu4ZnPtvCzb88m6XTX+T2ki3kOE3+sNGHKz2LCzOr+bjOz6TbTuXuaUuJRUJccOIwzh+dz7IXPicUUxw0qZTImKlMm19Ba9V6HB4f+YOKmFSei6tqBcGlc6j9so6tgShRZSdmuU0yB2aQMagIo3AQbbioagtS3WaJrflbQgQDHWJrXQtZSFdbfnLxFNPAMK1X0yE4ksXVEoVUjITdvqvYGlhJU6mIrcXXLXH7/fZUBHtbbK0vik2UHX4CT3+4kUk3v8Ent01mdIabC375Pu11Wxg//wnKvE6eax5AsKWe35w1mnfeWM2JhT42lR3DunkLyCgZxtAJoxhp1LH6zZW0RmIcmu0h/yvH8EV1O2vX1NNetwUxTNILBlE6IINDyrIoTncQ3bKa5vWViQIq8cQsl108JdNp2fOtAio+zIxszIxsYi4fUYeHYEQRiGwrttYeihKNJ2VF7AStSIxoJIKKRrex23ckasU6/W3iSVuJ/V2w8x/o9Fb0joiYwMPA6cAY4DIRGdPNqc8rpcbbLa5gkAv8FDgKOBL4qYjk7O6z9YtJX6PRaPYUhliLrlRaChwJrLYDWELAc8C5KQ7lVOAdpVS9UqoBeAc4bZceKgk96Ws0Gk0XTFvyZEcNyBeReUnt2i6XKgU2Je33JD1zoYgsFpGXRKRsJ9+7U2hHrkaj0SQRl2FIkVql1MTdvOXrwLNKqaCIXIclRDl1N6/ZI/1ipf/lhlqmTW7lqlOHMv+sOyk76kzeOvUGvnnDMTz4l/c47OzTWfKjOyj2OPBd+WOWf/g5OeVjufqIgcisp5mzqZkyr5MRF0xmbmU7G1fUEmypJy1/AEOH5TKuMJ3IqgXUL15B7boOsbVMh0lejoeMgTm4SgcT8+XTGIyytSVIZXOAykY/gfYwofY2wv7ti62JYWwjthYXWTMdlkxrvGiKy2Ha4mkd9v3uxNaSC6LHX7sWTUk2p3e1rRvS+fjuiq3truV+Z0z/S24bxY9/cSZVX8zi46NP5so37mHdR9M46tKv8sK1/+DS7x3NTx+by6BJZ5D30eOsbA1x+PeP4/cfrqd580oGHnIY3zhhKKH3n+bzihZ8DoOyYwdijDuB/62to66ilnBbE670LLKK8pkwOIcxBT58wXrC65fTvKGe+uYgzRFLbM0U8JpWjL47y4Unx4MnJx1PdgaGLxtJy0K50wlEYgSiMVpDlsBaazCSEFvzh6JEwlFikRixqCKm1DZia7EksTVtn+87ejEjtwIoS9rfRnpGKVWXlK/0GHB4qu/dFfrFpK/RaDR7il5OzpoLjLCLR7mwJGmmdb6flCTtnkNH/ZEZwCkikmM7cE+x+3YLbd7RaDSaJATpNRkGpVRERL6HNVmbwONKqaUicg8wTyk1DbhBRM4BIkA9cKX93noRuRfriwPgHqVU/e6OSU/6Go1Gk8RO2vR3iFJqOjC9S9/dSdt3AHf08N7Hgcd7bTDoSV+j0Wg6sb/LMPQLm76KRvjjsd9jyAtvcMUdTzPtpyfz+uZm0u/6KzVfzuaJKw7ntddXccbxg/j7F/XUr13EQUcfyoBNn7DqiZfZEohweImP9KkX8tKiLdSvW4YYJtllI5kyupASs52mhQupWbSBje0R/NEYLkMSiVmZ5SU4B5QT9RXQ4LcqZm2u99PWEiLoDxPxt1rJWd2JrZkmpp2YlZykZTlwkxK0ErG/5jaxwKadlOU0BKfRIbZmJJy2HYlZ0CG4lkjSYvsJUskfgoQDuJvztpfQtad5aOTZvHDczfzonu/zwhfV3N9+KEOPO5e3rj+S2fV+8n/6NzbOns4t35zAx3f8izKvk/yrb2X6u6sxXV7OPn4I54/KZ+Xzs9jkDzMs3cXgkw5js+Tw/pKttGxZDYA3bwB5JT7GlWQyJNuDo34DTWsqaNzQRE0wij/aIbaWbloVszzZHktsLTsDd24WZlYeMXc6MVc6/khnsbXWQIR2W2wtGIoSiyoi4Win5Kxuq2YlErRiKYutpdp3wKOLqGg0Gs2BQ1xPf39FT/oajUbTBT3pazQazQGCsZ8XUekXk/6I8iL8q1s59q63ad26nqy/3cy5g7O44JE5FB86haJ3/sCWQITD7r2Rbz27BGd6FjefPooNj9zI/LfX4TWFkeeMpiJjGB8v/Ji2mk24M3IpHpzD5IE5GBs+o/rz1dSuqKM2FCGqINdlUOxxkDUwk/RBpaicATQEY1Ta9vzKJj/+1iBBf5hwoJVYJNwpOWub4ilOl2Xbd1r2fIfTtOz58QQtOzHLNASX2bmQitMwcJpGIjEruXjKNglXSKfErOQFS7LYWteFzM7a63tbbG1n3QUFbpPv3PQgtTeWsOqCgzj+V0/y2XO3s+qqCzlvaA6XP7OItLwBXDU4wh0r67j05CG8Wethy6JZ5I88gisOH0ju+o+Z8dEmogpGD88h84QzeX1jE1vXN+JvqMJ0eckoGsy48lwOyk+jJM0gNG8pTWsqaNnaRlN4W7G1dK8jIbbmycvEyMrDyMgm4s4gjEEwGqE9HKUl1FE8pTVo2fXjQmvRaAwVU/ZrRyJWcmIW9GCj347YmiZFejl6Z1+jX0z6Go1Gs6cQtq1Gtz+hJ32NRqPpQl/Ige8r6Elfo9FokhCsmhX7K/3CWyEb13DL9J+x7qNpXHXLNfzl/vc5ZfofmP+fV7jrO8fx9g+f5aTCdJYOOI71n73PoCOmcFpxjMXPf8GipgCHZnkYeNF5vLmqjsqVG4hFQmSWjuToMYUclOcmsGQ2NctqqahupyncURA9szSDzCHFOAYMIZpRREMgSkVzgK1NfuqaAgTawoTbmogG/UR7EFuz4vKdnQqiO5xmtwXRO8XlGx2a3l0LopvSUTylq9hadwXRDZFubeY9LWaSu/eU2NrOcummeQyedAr3XPE4uX9/GTEM0h++mcdfXM5JL/2KD557g8kXnMrau28lFFMcctd1/HraMsJtTYyZPIKhbavY8tyzLGkOMsDjYOjJo2gbOIE3l1RSv3ENsUgIT1Y+uSUZTBicTanPibNuLW2rV9GwtpGtgQjNkRhRlRyjb+DJ8ZCWn4YnLwtPXhZGVh7Km4ly+/CHYwQiitZQ1BJbC0RoCUYSBdEjoZgdo68Sdv1YJLSNkB+kVhB9R/Z8be/vAcHyn6XQ+iN6pa/RaDRJCOBMsRRif0RP+hqNRpPE/m7e0ZO+RqPRJCP913STCnrS12g0miR2pFXV3+kXhquapiDXbD6Ir3zrW/y+fBPppsH9lQNwen18O7+KGVVtnHTvufzguYVE/K1cftYo2l/6Mx/X+fFHFeNPGERkwjk89+kGGjctx+HxUTS0lCkj8vFWr6Dqs2VUbm5hY3uYUEzhcxiUeh1kD84ka1gpZvEQ2sTDlpYgWxr9VDUG8LeECAbCRAKtREMBYt2IrZnODiduXHTN4XJ2iKyZluiaI1lszU7M6nDiWqsOU+js0LWdt8liawmBtaTqWZ2csmybhNWd2Fp3JL9vm8SuHt7Tl/9xRlz3Iot/dhSjM9xMuXMGd/3kSh759fsM8Dh5KjqGQFMtj192KNOeWcLpZZlsHHk6X876lIySYdx04ghqX3yCZS8spCkc4/D8NIrPOJW5W1pZ9mUNbTWbEMPEVzSEoYOzObQoE0/jRqIbl9O4ahPNm1uoD3UWW/M5DHJcDtuJm4EnLxNHdi5mRjYxl4+ow4M/omgLRWkJRmgJ2RWzQlHaQ1FCSclZcaG1aCSSSMxSsc4Vs6wW6/Q36ZqY1emYdtruFPH/bztq/RG90tdoNJokRMBp9ov18C6hJ32NRqNJYn837+hJX6PRaLrQX003qdAvfsMUF/l44aFHePv8bB4/6Wa+//Bl/O7BFznzyvP59IqbGelzEb3sx3zxziwKxxzDd48ayII/v0trJMZIn4uRXzuZd9c1sm5JJeG2JnzF5YwbXchhJT5CSz5m6/wK1rWFaQhbds8cp0leQTpZQwpxDRxKNKuYOn+UypYgG+raaWsO0t4aItjSTNjfSiTkJxYJJcYbT8xKJGc57cIpbm9nkTWHgWEnZsXt+O4uCVqGWIJrDtOwbfngNGUb236yHd+gczJWXGgtjiF0Od79J3xPBTDsyqKqtWodz4+YwuWLXmLz3Le4IfoJpgjf/t1F3P3QO4w6+Ryc//oZa9pCHHvP+dz13+W0VK5h+KQjmVIQYem/5/DZlhaynAbDTh2KOvQU3lhaRc26zYTbmvBkFZBXVsjRI/Ipz3ahNi0nsHIJDatqqGkKJBKzTAGfwyDXZdqJWV48eVmkFeZgZOaBLw/lycAfieGPxCxbfshOzApEaAmErcSssNViUSsxKxbtXDwlFtu2gEp3pJqYpekZQTr7yrbTUrqeyGkiskJEVovI7d0cv0lElonIYhF5T0QGJx2LishCu03r+t5dQa/0NRqNJpleVNkUERN4GDgZ2AzMFZFpSqllSad9DkxUSrWLyHeA3wCX2Mf8SqnxvTIYm36x0tdoNJo9hWXTT62lwJHAaqXUWqVUCHgOODf5BKXUTKVUu707GxjYi4+zDXrS12g0miTiMgypNCBfROYltWu7XK4U2JS0v9nu64mrgTeT9j32dWeLyHm98Hj9Y9JvzS1l+PHn8MrES1neEuTjyd+lvW4L/zxnMM9/upkL/m8yN762jNaq9Zxy5qG433+MWavqKU9zctShRThO/CZPzt5Aw9pFGA4XhcNGctrBReS3b6F29gKqV9fTEI7ij1ox+sUeK0Y/Z2QZzkEj8btz2NoaYmNDO5WNfvytIQJtITtG399tjL6YphWj7+yI0TcdDtue331BdFMkYc93OQxcpoHT7IjRdybs+h1Ca8kx+p0E12T3CqIbPdj8U43R72s++/ctrGkL85WntnLKdVfx+AW/5Lq7T2XVabdSvexj/vndo3n9p28wKddL9IIf8eGb8/HmFPN/Z44i8Nrf+HR1A1sCESZkexh8zlSWtxh8vKiSlso1AKQXlDFgUDYTSrLIDNQSXL2Y+i830LCuka2BKK2RrgXRDdLyvXjzfKQV5uDMzsbMKSDmySDq9tEWjhGIxCx7vh2j3xq04vT9gQiRcHJ8foxYTCU+V11j9GHbgug7G6Ovbf7bQbD+f6XQgFql1MSk9ugu31bkcmAi8EBS92Cl1ETga8DvRWTY7jwa9OGkLyIeEflMRBaJyFIR+bndP0RE5thOjedFxNVXY9BoNJqdJb5Y6iVHbgVQlrQ/0O7rfE+Rk4C7gHOUUsF4v1Kqwn5dC3wAHLbLD2bTlyv9IDBVKXUoMB44TUQmAb8GHlJKDQcasH7OaDQazT6C/Ws6hZYCc4ER9mLXBVwKdIrCEZHDgEewJvzqpP4cEXHb2/nAMUCyA3iX6LNJX1m02rtOuylgKvCS3f8kcF5fjUGj0Wh2lt5c6SulIsD3gBnAcuAFpdRSEblHRM6xT3sA8AEvdgnNHA3ME5FFwEzg/i5RP7tEn4Zs2uFK84HhWGFLa4BG+w8B23Fq2A6RawHyiktJ68uBajQajY3YuTC9hVJqOjC9S9/dSdsn9fC+T4BxvTYQmz515CqlonaM6UCs0KVRO/HeR+POkYaWMAvuPYFZte388NYTuObnr3HUpV9l+bVXkOsyKfnJH5nx8ixyhx7KT08ZwYLfvMjWQISjxxYw7uopfFpnsHj+FvwNW/EVl3PQmAKOLssi8sUstsxZy+rWcMIxl+M0KcnzkjOiAE/5MKJZA6jzR9jU5GdDXTvNjQHaW4IE21oJtTURDQW2ceImC6zFXw2nC8M0cDhNq7ms1+SErE5OXEeH09Yw4olYJBK2OippdXbewnYqYomknJi1u6SeuLJr198wZSp3vv9r5r/4NK+daLKyNUj9lb/isvtnMvjoszlo7hPMrvdz+m0n8dN31lC7ci5DJh3LpaOy+eIfM9nkD+NzGIw6YTCOyefxypKtbFlVQaCpBndGLrllZRwzIp/huR5k8zLql6yjYUUlNbV+GsJRQjGVlJhl4MvxkF6UjrcgB1deLmZOIUZGrpWYFbYSs5ps521r0ErM8ociBJMSsyLhmFUxS6lEtaxYJNQpMQu0E3ZPEA+K2FHrj+yR5CylVKOIzAQmA9ki4rBX+906NTQajWZvYuy1uLS+py+jdwpEJNve9mJlpC3Hsk1dZJ92BfBaX41Bo9FodhZBr/R3lRLgSduub2A5MN4QkWXAcyJyH1b68T/6cAwajUaz0+zHhbP6NHpnsVLqMKXUIUqpsUqpe+z+tUqpI5VSw5VSFyfHpPaEw+vj/YOP5Yc/PJaq7/yO2pVzeev6I/nXKyv4+pXjuXnGBhrXL+H4sydTOO953ptfyQCPg0OvnYr3rGt45ON11KyYj+FwUTB8DOeNL6UkXEPtx7OpWlJDVdDyK3tNodTrIGdoNrmjynGVjyKYXmAlZjX62VDbRnuzZc8PtzURDfmJBLsRW0tKzDIcLkyXF4fLjcNlbpOY5XWZ3RZPiSdmOQ272YlZTqMjMStRRCUpMStRSAXrWFxsLZXiKf0lMQvgrZV1nD63kMmXf5Onj7qCG248lgt++T4bP32DR354LP+97jEOzfKQecMD/Oc/83Fn5HLdOWOIvvFnPllYhdcUDs1yM+LiKayMZPP2/AqaK1YC4Csqp7g8m8mDc8iLNBBa+Tl1yyuoW9XA1kCkU2JWpsMk12WSXphOemEGaYU5mDmFmDmFxLxZxNwZtIdj+MMxmoIRWkJRmtrDCbt+KNg5MSv+qmLbL57SXWJWdzZ/nZi1C6S4yu+vK/2UJn0RuUBEVolIk4g0i0iLiDT39eA0Go1mTyO9G6e/z5Gqeec3wNlKqeV9ORiNRqPZF9ifzTupTvpVesLXaDQHCvvxnJ/ypD9PRJ4HXsWSVwBAKfWfvhiURqPR7C3293KJqTpyM4F24BTgbLud1VeD6srYsize3NRM1ff/wPl3/IdJX/s6q666EJ/DYNBvHuOlZ2aSO/RQHjhnDAt+8SRbAhFOOKSQtHOuZXZLOnPnbKa9bgu+4nLGjCviuMHZxL74gIpPVrOiJURrJIbXFPJdDkryvOQdVIh32AiiOWVUt0dY3+BnbU1bIjEr3NaUUmKWw+XFdHlTTsxKbqkkZsUdtdA5Maunn6b7S2IWwC/f/yUfPvEEM8/3saAxgP+Wh1n30TQGTT6Lycue5d3qNs677URuf3MVVUtmMfToqXzrkAI+/9N01rSFmJDt4ZCp5ThPuJSXl1RSsdJK3nNn5JI3uJwpowsZnZ+GUbGM2oUrqVvVQHV1G7Wh7SdmuQvzrcSsrHxi3izaI4q2pMSs5kCYlkCE1kDYTsyynLfxxKxoNGYlZIVDPSRmxVL+G2mH7a6zPztyU1rpK6W+1dcD0Wg0mn2FfqE5v4ukGr0zUEReEZFqu70sIn1a3UWj0Wj2BmL/qk6l9UdS/UJ7AksOdIDdXrf7NBqNZr9jfzbvpDrpFyilnlBKRez2T6CgD8fViaYvlnPb3adw/i3PULtyLm9/+xAef3E537z+SK57fS31axdx2oVfoeCTJ3n7sy2UpzmZcMNpfNjk5fcfrKZ6+VwMh4uiEQdz8eEDKQ1VUv3BR2z5ojqRmJXvclDqdZA3PIe8g4fiGnowgfQCKppDrKtv75SYFUohMct0exNCa32VmBVPxkpOzEqumJWcmJW8KOnviVkAUz8pYsq3r+axwy/nlp+cwpl3v83Q487l2dun8NJVf+WIHA9pN/yWl174FE9WAT+4aCzhlx7ggwVb8TkMxp88hJFfO4Xl4Symz9lE4/olAGSUDKN0aA7HlueSH64jsGQ2NUs2U13dRoV/+4lZ6SV5mDmFSPbOJGZZYmvJiVk9VcxKTr5KJTGrO7Sdf8cI1v+RVFp/JNVx14nI5SJi2u1yoK4vB6bRaDR7CxFJqfVHUp30rwK+CmwFKrEE07RzV6PR7H/YEXCptP5IqtE7G4BzdniiRqPR9HME6MUaKvsc213pi8iP7Nc/icgfu7Y9M0Rojcb48Ly7adq8knO/exXzzz6PAR4n2fc8xrSn3qBwzDH87uxRzP7JU2wNRJhy9ECc59zAb99dxYLZm/A3bCVz4EgmTCjh+MHZhOe/zaYPVyVi9H0Og0FpDkoL08gbMwDv8FFEcgdR1RZhfaMVo99U76etOUCopZ5IoI1woG0be348Rt90eROvDpe7Iz4/KUbf6zJx23b9NJdp2/cte75lvzdwmEYiRt9pdlOuzbasG0m2/Y5/u22F1nYmRn9Xf7ruiRh9gLkvPMPr4zaxyR9m+dfuo2LudF69cwoj3nqAj+v8XPTARXzn5SXUfDmbg6acyOXDXMz97XQ2+cNMyvUy4orzMKd8g3/O3cSmpWsJNNXgySqgYMhgTh1XzJiCNFi/kJrPV1G7oo4Kf6RT8ZQsp0muyyAjL42MAT7SivNwFxZg5hVb9vy0HNoiitZwjHp/mKZAhIb2EI3tYRrbQ/gDltBaxI7Vj9v2t188JbZdAbUdCa1pUudANu/EpRfmYZU97No0Go1mv8IKhOg9846InCYiK0RktYjc3s1xt4g8bx+fIyLlScfusPtXiMipvfF82zXvKKVetzfblVIvdhnoxb0xAI1Go9nX6K01vF1P5GGsIlKbgbkiMq1LgfOrgQal1HARuRT4NXCJiIwBLgUOxgqVf1dERiqldutnXKqO3DtS7NNoNJp+Tjem1B5aChwJrLbriISA54Bzu5xzLvCkvf0ScKJYtqNzgeeUUkGl1DpgtX293WK7K30ROR04AyjtYsPPBCK7e3ONRqPZ59i5xKt8EZmXtP+oUurRpP1SYFPS/mbgqC7XSJyjlIqISBOQZ/fP7vLe0pRH1gM7it7ZgmXPP4fONvwW4Ie7e/NUKR1ezHU/fJjv3Xkd949p4/++tZH7H/ka5z02l7aaTdx48yUYz97Hf5fUMDbTzaE3X8Yra9tYMnsNdasX4PD4KBs7hq9NLKOwcRXr3/mQ9ctq2RKIYAoUuR2UDsggd0QO+YcMwzFkLE3ObDbWt7G6ppX11a20NgYItjQTamsiEvInEmjiGA4XptOF6fJgOG1nrtub5MQ1Eq8u22nrdTlwmZ2F1pyGJbJmCrYDt0N8rWtiVvyDmSy61p1CYLLQWqqJWV3fn0xP/x/2pDLhz3/7I+49+TTufOEHDP7Rvzj84q+T8bdb+fsDMzl7YCY159zGjCv+SEbJMO67dDwNf7+XmSvrKHCbjL/4YDju63y0pZ3352ykcdNyxDDJKhvNqFH5HF+eR07rJlo/n031os1U1vmpDXUkZnlNg0yHQZHHScYAH+nF2fhKCzDzSpCsQqJpOUSdabS2R2gJRmkKRGgKhhOJWa2BjqSsWFQRCVnJWdFIJCG0tr3ELKBTYlaqaOduaohSSOp/q1ql1MS+HE9vsyOb/iJgkYg8rZTSK3uNRnNAICp1NdMdUAGUJe0PtPu6O2eziDiALKzk11Teu9PsKGTzBXvzcxFZnNS+EJHFu3tzjUaj2fdQoGKptR0zFxghIkNExIXlmJ3W5ZxpwBX29kXA+0opZfdfakf3DAFGAJ/t7tPtyLzzA/t1j2nnazQazV5HqV66jIqIyPeAGYAJPK6UWioi9wDzlFLTgH8A/xKR1UA91hcD9nkvAMuwfKjf3d3IHdixeafS3qwF/EqpmIiMBEYBb+7uzVNlbSgNd1Y+96bP58XJ93NGsY9Vp93KZ5f8lOHHn8Md4728dvlrhGKKky4eTcvRl/OHP39KzfLZREN+CsccwymTBnH84CzaX/wrG2auZWVriFBMkesyGZLupHBcATkjB+I5aDyR/KFUtkZYVdfOl5XNNDdYiVnBVisxK253jWM4XInkrETxFLcXh8vZkZDl6kjQcjkM0lzdFFExjYQN32Fvby8xy0jY6ZOLqexYaK1TwlY3f+++Tjrpjctf+tZ9fJLh5i41FX/dP/nghqu5L/9aWiMxbnzpN3zlkTm0VK7h1O98m5Md63ntd+9TE4xy4ag8yq++itfXNvPcvE1ULF1KuK0JX1E5A0aUcsa4Ekbne4h+OoeqeV9S+2VdQmgtquJCawYFbpP0ojQySnz4SgtwFZVgFpQSS88l7PDSHorSGrISs5qDEZrawzT6rcSsYDBCOBi1ErNCUatwSrx4Sjw5K1lwLRbtlJgV6yYJa0eJWdqevxMoleoqPsXLqenA9C59dydtB4BuQ+CVUr8AftFrgyH1kM1ZgEdESoG3gW8A/+zNgWg0Gs2+gqhYSq0/kuqkL0qpduAC4C9KqYuxEgY0Go1mP0NBLJJa64ekWhhdRGQy8HWs7DGw7FMajUazf6HoVfPOvkaqk/6NWBm4r9jOhaHAzD4bVReaqmtY+PDV/HHkEaxvD/GnL59m5P0zcXp9/OW7k1lzxzW8W93GWSUZjLzjTu7+eAOr5ywgGvKTljeA4ROH87UJpbiWvcfSN+awbEMTNcEILkMo8zopGZFLwaFDyRw5FCkbTW3Eycq6ZpZtaWZLTRst9X6CTTWE25oShVPiNlIxTMQwcbi9mC4Pptsqhm66vEkCa3aMvsvAnRBYc+B1JgmtxWP0RRIFVKxtAzPRZ3Qbox8vht6TqTxu47e2O0TaktlTMfq95S64/zf/44+N87jqpB/zk/tv4rOTz8AU4aqLR/OccyKL//sbBhx+Kg9fNI5l37+EmTXtjM5wc9h3TmDr4GN5+JmFrF9WTcuWNTg8PvKGjeOYQ0s4ZlA2ni2LqZozh6pFW1nXHKQ2FCFq+/V8DoMCt4OCLA+ZAzPxleaTXlqAWVCKysgnlpZDSyhGWzhmxeYHI9S1h6hrDdHUHqI1YNvzwx1Ca9GoFaMfj8mP2rb95FyQ5MIpwE7H6Gt2BgU7UYC+v5GqtPL/gP+JiE9EfEqptcANfTs0jUaj2Tv0V3t9KqRaGH2ciHwOLAWWich8EdE2fY1Gs3/Se3H6+xypmnceAW5SSs0EEJETgL8DR/fNsDQajWYvoRTsxyGuqU766fEJH0Ap9YGIpPfRmDQajWavcsCbd4C1IvITESm324+BtX05sGTSc/Mwbv0abdEYN1wzgRu+yGDjp29w0uXnMmnd67zw9BIGeBx85d5z+ViG8eL0FTRtXE7mwJGUjDuSq48fxiijnqo3prHhw02sbw8TVZbQ2tDCNIoPLyVr/HjcY44kkD2IDU0BVtS0WolZdX7am5oJtTdZiVmRzkJrYpgYTheGw4nhTErMcpo43Q6c7s6Ca17biesyOxKzvC4Tp2ElY8WduE7Tcuxa20mCa0ZHYpbYFbOgQ2ita2JWd47T7QmtJSdm7atOXIAf3Xg04378EQOPOIWb/O/w9OwKrr3rZIY/8R/ufOhdTKeL2645ivx3/sSbr63CFDj+5HKyLv0+j8+vYOW8ddR8OY9YJETWwJEMHl3AWQcXMUiaCMx7j61zVrF5bSNVwQj+qFUty2sKOU6TYo9J5sAMsgbnkDGoCEfRIMy8AcTS82iLmTSHorSGotS2h2nwh6lvDdHkD9PYHiboDxMJRRPOXMuJ25GYlRBbi3ZOzEom7sTViVl9Ra/KMOxz7Exh9ALgP8DLQL7dp9FoNPsf+/GkvyM9fQ9wPTAc+AK4WSkV3hMD02g0mr1CL8sw7GvsyKb/JBAGPgROB0ZjxexrNBrNfomwf9v0dzTpj1FKjQMQkX/QC7Keu8LILMWfn1nKg89cw+YTb+DJi+5h0OSzeObig3h3zLepCka4/pIxGJfdxY//OofNn/8PZ3oW5RMO45jxAzh7ZC7h//6BVa8vZmFjgNZIjCynwXCfk+LxRRQdOQbnyMOJ5Axkc0uYZdWtLK1oor6mjdZGP4GmGsJtzYnErDhxkTWHnYzl9PhweH04PR5cbkdS4RQzYc+3ErM6Xr0u0xZakyQb/vaF1iTJnh9PzOpqz0+mO6G17tiePb8n9mThlGReveBeNt7yOyrfe4DfFR7K+SNyabzm13ztr3OoWjKLY664km8PbGPGxc+ypi3EuYOzGHPLtbzfkMbL7y2jdsVcIoFW0vIGUDpmBJceWcYRA3ww/z22fPg5WxdWsa4tTH3Isod7TQOfw6DYY5Jd4iNzYAYZg4rwlJXhKB5E1JdPyJVBiz9KcyBKUzBCgz9MbWuQurYQje0h/HZiVigYSYitRUJhK+nKFvHrSWgtIcK2k/Z8za6gYD9OftuRTT9hytnZIioiUiYiM0VkmYgsFZEf2P25IvKOiKyyX3N2YdwajUbTN8RlGPZTm/6OJv1DRaTZbi3AIfFtEWnewXsjWD6AMcAk4Lt2dffbgfeUUiOA9+x9jUaj2WfYn1U2d6Snv8uiarYWf6W93SIiy7GK+p4LnGCf9iTwAXDbrt5Ho9FoepcD25HbK4hIOXAYMAcoSirOshUo6uE91wLXAmSJg7+cdCxPDbmcX9/5JqbLw7O3T2HV9V/n9c3NnDc0hzG/+iW3vrOGJe99TLitibKjzuQbp4zg5GH5pC99m6UvfMCSVfVU2UJr5WkuykbnU3LkSDxjJxEuOohaf5Sl1c0s3NTEuooWWur9+BuqCbc1Efa3dm/P70Fozekxcdlx+qbDwOtxbCO0FhdbcxqCx47bT8TndxFac5odtnzT6GzP786q3hHHn/h7Jvph2xj9Hdr7t3t0x/S26f+OG+/nwT/fyYKjTyCqFFNnvcjYX7zPxs/eYdDks3j2W4ez5KoLmF7RzNhMN5PvPJPKkady/78WsHHBHCKBVhweH0WjJzJ14kBOHJpL+uYFbP3f/9g8exNrGgIJoTWXIeS7TLKcJgVZHrIHZ5E1pJiMwQNwFJWhsoqIpefREorRHIpS2x7aRmitsTVEKBAhHEwWXIsmhNVikdA2Qmtd7fnbQ8fn9zJ60t91RMSHFdt/o1KqOXlyUUopEem2LplS6lHgUYBSw9M7tcs0Go1mR+znMgypJmftEiLixJrwn1ZK/cfurhKREvt4CVDdl2PQaDSanUOhIuGU2u6QSlCLiIwXkU/tYJjFInJJ0rF/isg6EVlot/Gp3LfPJn2xlvT/AJYrpX6XdCi58vsVwGt9NQaNRqPZaRTWSj+VtnukEtTSDnxTKXUwcBrwexHJTjp+q1JqvN0WpnLTvjTvHINVS/cLEYkP5k7gfuAFEbka2AB8tQ/HoNFoNDuFQu2pIjU7DGpRSq1M2t4iItVYkjiNu3rTPpv0lVIf0bP/78SduZbDgOLnXuf2i39JoKmGu+6/hRFvPcB9LyxnbKabEx7+Di82FfDSK+/TUrmGvOETOOWk4Vx+SDHZdStZ/8xzLJu1iZWtliO2zOvkoEGZDDx6GNlHTSY2eDwbWsJUNAdZvKWZ5RVNNNa00VbfQKCphlB7M9GQv1O1rK5O3HhiluW8dSRVzTJx2U5bn8eJ19mRmOVyGLYD18RhdjhxDdlWaE0ETFtErasTd0dCazty4nZlXxZaizPhwks5/+37ufeLah565Qec/lIl6z6aRkbJMB7+wbHII7fz8n9Xk+syOe0bh+K5/C7umL6aLz9eTFvNJtLyBpBRMpzxhw/gkvGllIW20PLhm2z635esX9fIJn84IbSW6zIp9jjIdzvIGZpN1pB8soaV4hgwBKNgEJGMIpqjJk3BCDVtIWrbwzQFw9Q0B6lvs5y5oWDESsqyq2V1deJ2J7QGXZKvolGdjLUnUOxM5ax8EZmXtP+o7Y9MhZSCWuKIyJGAC1iT1P0LEbkb+5eCUiq4o5vukegdjUaj6T/slCO3Vik1saeDIvIuUNzNobs63XE7QS32dUqAfwFXKJUILboD68vChRX0chtwz44GrCd9jUajSUap3XbSdlxKndTTMRGpEpESpVTl9oJaRCQT+C9wl1JqdtK1478SgiLyBHBLKmPq0+gdjUaj6X+oLvpHPbfdZIdBLSLiAl4BnlJKvdTlWDwKUoDzgCWp3LRfrPTzDx7BsTe+hMOTzrHnnc4d2Sv4/U0v4TWFS352BisPuYR7fzuLqi9m4Ssq55Aph3HTcUPJWDiN6o8+5Mv/LGNRU4BQTDHA42BsvpeyYwZR+JUjkZFHsSWaxqKtzWxoaGfBhgbqtrbQUt+Mv3Er4fZmosFt7fmG07WNPd/pduF0O3C5OwqoeD0OXA6DjC72fK/LxOMwOxdOsZOyDFtsLZ6U1bVwSqr2/GTxtV0tnNITe9OeD/C/KY3ccPQMfnTj0fwh6yw++sWDDD3uXL5xzmiOX/Myj9z3Nk3hGJefPITyO+/lj/O38uZbX1K/dhHO9CyKDz6CkiE5XDlpMOMyQoTee531M+azaXE1a9pCNIWtX9BZTpMBHgcleV58henkDs8ja1gp7rIhOAYMJZJVjN/w0NgepaYtTHVbiJq2IE3tYapbgtS1Bgn4w4T8VmKWZdePEgkFidoCfonErERSVkdiFtBJaC2OLpzSh8Sjd/qeboNaRGQicL1S6hq77zggT0SutN93pR2p87SIFGD9t16IJYO/Q/rFpK/RaDR7DrUzjtxdv4tSdXQT1KKUmgdcY2//G/h3D++fuiv31ZO+RqPRJKPYUyGbewU96Ws0Gk0n9m8Zhn4x6S+rCmCsW8QTf7mVC/JbePaQa9kSCPPd648gdOV9fPtPn7D247dwZ+Qy+oRjue+sMQytnc+Kvz/NlvlbmV3TRlM4Rq7LZFyWm8HHDaJ06pE4DjmOWk8hX2xpZd6GBjbUtVFZ0UxTbTvtdRWEWho6Ca0lx+cbDle3hVPcXgcurxO314Hb7SDDtul3VzjF47BE1tzxGP2kOP2uhVO6xur3ZM+Psz17fjI7sud3L+a2d+35AD85/laumDKYVdf/nl98+zfkjzyCV++cwoi6Bbx0wp9Y3hLkq+MKOfx3d/NijY+//2c+VV/MwnC4KBxzDFO+Us5XhuUxZXAmsQ+fYeObH7Hpo80saw4mCqdkOQ0GeByUZbnJG55DelE62SPLSB86FOegkUQziwm6s6hvj1DnD1PZGqSqNcjWxgAtwQh1rUFa2kIE/RGCgTDhQEfhlOT4/GR7vhWvv3uFU7Q9fzfpxeidfZF+MelrNBrNnkOv9DUajebAYc9F7+wV9KSv0Wg0SSgUag9E7+wt9KSv0Wg0yeiV/t4n2NLIb3/1PaZ+8CAzHniH2fV+rr9kDEW/eZKz/jqHJW9Px3C6GHn8VH5+4TgOj6xh7V/+wvzpq1nXFqYmGCXLaXBolpuhxw1i0KlH4D7iFBqzhrBkaxuz19czd00d7c1BGqpaaavZuI0TF0g4cR2edAyHC1d6Fs70LFxp6bg9TlxeRyI5y+124PM48HmcVnJWYt+qnOW2K2bFE7I88X0zLrhmJATXEglZ9OzEjZNcLQu6d+J2Vy2rt0XW+pqp5dlkPfM6Z175ezw5RTx9z7lk/O1W3nrsU2bWtHPu4CyOfeQ23jXH8Kun5rFh9ruoWJTCg49h8rGDuW7yYIbluDHmvcbGaTNY9+46FjUGqApa1bJ8DoMBHifl6S5yR+SSe1AR6SV5+EYMx1k+mmh2KcH0Aur9UeraI1S2BKlus5y4lU1+2kNRmlpDBNrCBP2WEzcUjBAOhogG/URD/oQTN+G01U7cfQOlUOHQjs/rp/SLSV+j0Wj2HHsmOWtvoSd9jUaj6cp+/ItJT/oajUaTjFL7tZmsX0z6xaVFXL3yCX55yys0hWNcd+5Ihj/xH856dC7zXnkNFY1y0NTT+dml45ni2sK63/2Wz55fwoLGAP6osu35Hg76ShlDzzoK79Fn0ZQ3kkVVbXy4to5PV9VSs7mZQHuItprNBJtqCbU1EQ35E2MwXd6EPd/h9WE6XDg8vk72fLedlOXxOvF5HGSnufC5HbgdhmXLd5kJe75VPMUqoNJh27ds+YZIJ3u+adCRoEX39nxDOtvzk5O19oY9v69N/yM++R9HfuthxDB56tffZNTLP+fPv3qXmmCUs0oymPrPH/Fp4fHc/vhcVn/0DtGQn8IxxzD5hIO4ecoIxho1xD7/nE0vvcrqN1exqKa9iz3fwTCfi4KD8ykYW0L+IcNx5uXjKh9FLG8w4Yxi6toj1LZH2NwcYGtrkIp6P5VNAaqbg4RCUQLtlj0/5I/0aM/XSVn7Jjp6R6PRaA4UlEJF9aSv0Wg0BwRKKWLhyN4eRp+hJ32NRqNJRqFX+nubwkAt917/DMPSXRx9yhCG/fM/nP7XOcx9+VVUNMrok87gl5dP4CTXZtY9cD+fPvcFcxsCRJVlz5+Q7WHUCYMZetZRpB13Ho15I/l8axsfrK7l4xU11GxuprGyilB7U0r2fFdaFqbbm5I9Py64lhyfn2zPT47Pj8fmG9L79vxUi6b0B3s+wMTLH8Jwunjxj9cy6rm7+cO9b2MKnD0wk5Of+zGzCqdwyz8+Y+XMt4iG/BSNO45jp47iRyeOYKxU0fr6k9QuXs2qN1awqKadTf5wJ3v+yAx3J3u+Z+RYzJxCYvnlhDOKqWmPUN0WZnNzgIqWABX1fjY3tFPdHKStJUQkHE3Jnp8oiK7t+fsUetLXaDSaAwSlFDGtp6/RaDQHDvtz9I4ujK7RaDTJ2NE7qbTdQURyReQdEVllv+b0cF5URBbabVpS/xARmSMiq0XkebuI+g7Rk75Go9EkEY/eSaXtJrcD7ymlRgDv2fvd4VdKjbfbOUn9vwYeUkoNBxqAq1O5ab8w72zZ1MARBblcOON3VJV/hRN/+xGL//sqTq+PcWedyu+/dhgTWhex4qcP8tHrq1jUFABgpM/NoDQHB50ylPKzv4Jr8pnUZJQzb3MLs1bXMmdlDdWbm2neupX2ugqioQChtqZuK2U5POm2uJolsmY6DNweJ550Z6dKWdlpTnweZ8KJ64tXznKapNmO3HilrO6cuKax85WyunPswp534u5JLTZvTjHv/f5SHPdewwN/m0uR28E37ziJogsu4cXwCH7+l09Z/8kMAAYcfionnzScm44fygj/WupfeZKVL8+jYW0jCxr8iaSsLKdBmdfJsBwPBWPyyR83kPxDhuEaejBG2Shi7gwC6QXUtIWpbguzsSlApe3ErWzyU9kYINAWJtBuOXJ7ElmLhPyoaFQ7cfdhYnvGkXsucIK9/STwAXBbKm8U6z/yVOBrSe//GfDXHb1Xr/Q1Go0mGTtkM0XzTr6IzEtq1+7EnYqUUpX29lagqIfzPPa1Z4vIeXZfHtColIr/3NgMlKZy036x0tdoNJo9xs5l5NYqpSb2dFBE3gWKuzl0V+dbKiUiqofLDFZKVYjIUOB9EfkCaEp1gF3Rk75Go9Ekoei96B2l1Ek9HRORKhEpUUpVikgJUN3DNSrs17Ui8gFwGPAykC0iDnu1PxCoSGVM/WLSz0lzcsGS6Xzr7Vo+e/wd1n00jYySYRx93lT+eMFYBix+hfm/+ScffbyZla0hvKYwNtPNuCMHkHdQIaWnT8WccAqbjDzmrG/k/RU1LF1bT21FM81bN+Nv2EqwpSEhfAWWPT85KcuVnoUzLQtXegYurxPTNPCkO3F7nbg8Drye7u35XpeJ07Ds93F7vsdh2fQt236HPb+TDT8Fe37chp6KPV+6GNz7sz0fYPUT3+TzU0/hqVkbmZTr5at/+Sbrj/8uTyzdyiP/ep+qL2bhSs9i0MTjueT0kVw9cSBFGz9my4vPs+KVxSze2ERDOEpNMIopUOA2KfM6GVKcTsGYfAoOKSdnzDBcww+B4mFEsgfSHlHUtUbY0hKkojlARXOAzfV+tjb5qW0OEmgPE2gLEfRHiEZjhIMRwoFAwp4fjVjJWB0ia+FOdvvt2fN7sttre34foBSx0B6RYZgGXAHcb7++1vUEO6KnXSkVFJF84BjgN/Yvg5nARcBzPb2/O7RNX6PRaJJREIvFUmq7yf3AySKyCjjJ3kdEJorIY/Y5o4F5IrIImAncr5RaZh+7DbhJRFZj2fj/kcpN+8VKX6PRaPYUij2jsqmUqgNO7KZ/HnCNvf0JMK6H968FjtzZ++pJX6PRaJJRJMxs+yP9YtJ3jxjJ5IdXsGT6K8QiIUoOO4lrvz6RWyaV0P7UL5j1x3eYta6RmmCUArfJETleRpw2lMFnHYerfDTRUcexvCnGrA21zFxezfp1DdRXtdJatS4hsNa1ALrp9uJweXGmZ+L0+BIF0D1pLtxeB4Ydp+/2OshIc5LhcZDldZFh2/F9HgfpLgceh1UUxe2w7fpd7PjJBdDjsfkGtv3etutvLzYfugivJf3ddseev6/a8uO8NPAwPq7zc+nhJRz33EM83TyQ+37xPrVrltJSuYaMkmGMOm4y3z/9IM4bkQ2znmbV82+w6q21LEwqgO4yhCK3gyHpTgYOzbbi8w8ZRsbo0biGHkwkdzDBtDxq2iL4wyohsLa5wc/mBj/VzQEaW4KJ+PxwIEowEEbFFOFAO9FgR2z+9gqmgDXR6Nj8fQGlZRh2BRF5XESqRWRJUl9KaccajUaz19i5OP1+R186cv8JnNalL9W0Y41Go9krKKWIhiIptf5In036SqlZQH2X7nOx0oWxX8/rq/trNBrNrqFs89uOW39kT9v0U007xk5nvhagdGBZtyltGo1G0+voyll9ww7SjlFKPQo8CuDMGaSqpz1P8aFTKBtVmhBYW/m9W/jw1ZUJgbXRGW4OG53H8LMPpeDU04mNPp7aqIN5G1u7FVgLtjQQDfkTTrHtCaxZlbHsKlkeJw6X0aPAms/jsKtjWQJrlqhazwJr8SSshNN2BwlZ3TlwYf8WWOtKhT/C3feejvsHD3LB84v56LV/07x5JabLS+kRZ3QWWHvkt6x8eR6Ll9Swpi1EaySGyxB8DulRYM0cOJJwziAaog7qmqwKWU3BSI8Ca0F/xErGCkYIB9pR0WiPAmvxpKxkBy6kJrCmHbh7AAUq2uPU1O/Z05N+SmnHGo1Gs7dQqD2lsrlX2NMZufG0Y9iJtGGNRqPZYyhQMZVS64/02UpfRJ7F0orOF5HNwE+x0oxfEJGrgQ3AV/vq/hqNRrMrKAXR0P5rRuuzSV8pdVkPh7ZJO97htaIRjr/6Kh7+6iEMcbbT+I+f8dYfZjKrqpWmcIxij4Mj8tMYfvpwBp1zIo6Jp1HpKmLuumY2NPqZubyazRsaqa9soK1mI8GmWsL+1m2KpRhOF05POg6vL2HLd3m9tj3fkSiWkuZ14nIYZKe5thFXiydkJYurGWLZ8S2bvmXLN6RzQlZviqvB9m35ye9Jpj/Y8uPcsuJV/rYpjQdvns6W+TNweH0MPe5cisuzueW0UZwywCQ68x8se/4dVry/gSXNQbYGrBC7XJclrlbgNikamk3huCLyDxlG+shRuIaNI5IzkBZXNrX+qGXDbwmwpTlAU3uYyqYAlY1+mu2ErGAg3GHPt8XVYrawWrSTuNq2CVm6WMo+ilLapq/RaDQHEjE96Ws0Gs0Bgg7Z1Gg0mgMHBcT6qZM2FfSkr9FoNMkopR25e5sR5YXMmBph5W2XM+uzSv63pp6aYJRcl8mpRemMOLGcoecdj2vymdRmlDNvSyuzVm9gzsoa2pqD1FW20FazkUBDVSdFza7JWIbDZVXIshU13R4nnnQnLq8Tl9vE43UmkrFcDoMMd0cyltdpkuY0Ew7c5GSsuCO3J0VN0+jZgQt06oNtHbid+vZzB26ccQ+uYf0nMwAYcPipiWSs8kwnfPgMax98ndXT17CgwZ9Q1MxyGp2SsdKL0sk7eAiZY0bhHDqWWN5g2tILqGmPUF1nV8Zq7kjGaglEtlHUDAUjhIOhRHWs5GQs7cDtnyidnKXRaDQHEHrS12g0mgMJnZGr0Wg0Bw57KCM3lfoiIjJFRBYmtYCInGcf+6eIrEs6Nj6V+/aLlb5sXMufJ13H8pYgAMUeB2cPzNw2GauimZlz1rBwdR21W5pp3rqFUHtTj8lYTq8PR1Iylun29piMleFxkJWUjOVyGD0mYzlNy5bvtpOxTIO9mozVn4XVemLj3JkMnnQK558ygusnDWJgzeds/dutrPpyU4/JWEML0ygck0/+2DLyxg3HyCncNhlra3siGWtzvZ+tTX6qGgME2sNEQtEek7Eitj0/noxlNW3L748o9licfry+yP0icru9f1unsSg1ExgP1pcEsBp4O+mUW5VSL+3MTfvFpK/RaDR7DKWI7ZnonXOxpGrAqi/yAV0m/S5cBLyplGrfnZtq845Go9EkoZS10k+l7SYp1xexuRR4tkvfL0RksYg8JCLuVG6qV/oajUbThZ2oipUvIvOS9h+1a4EAICLvQrc1oO7qdL8d1BexpejHATOSuu/A+rJwYdUeuQ24Z0cD7heTfk1TkCZPlHMHZ5E7IpdhZ08g56SzCQ6ZxJIaPx+sqGPm8sVs2dhIw9bGTqJqcZsqgOFwYbq9PYqqOVwGbo9dKMXrxOdxbCOq5vM48DhMS0DNtGz5TjMem99ZVM00BAPLXm8adGzLju340CVW3+7ryY7f9Vjye7qSii1/X7TjJ/PSY7dzYrEQee8pVn3nPWZ/YNnxWyMx/FGF1xTK05wM97koGZFL4bgicg8egm/UGJxDDiaSO4iYO4PKINT5I2ysaqGiOcCWRj+bG/xUNwe2EVWLRWKEghGiIX8iLn9HompAImYftB2/X6B2ahVfq5Sa2POl1Ek9HRORnakv8lXgFaVUOOna8V8JQRF5ArgllQFr845Go9EkY8fpp9J2k52pL3IZXUw79hcFYq3+zgOWpHLTfrHS12g0mj2FYo8JrnVbX0REJgLXK6WusffLgTLgf13e/7SIFGD9qF8IXJ/KTfWkr9FoNMkoRTTU95O+UqqObuqLKKXmAdck7a8HSrs5b+qu3FdP+hqNRpOEUhBTWoZhr1Jc6OO2p+9Cxp+M35vH4qp2Zq2rY+b786jZ3EzD1jraqjcSam3YJglLDBOH14fTk44zPQunx4czPQtPeloi+crtdeLyODAdBllpTjI8TrLshCyvy0w4b+OCak5DEglYVjKWbOO81UlYfUvhrZfz/KebWd4Soj4UxRQrCWuAx8lBGS7yR+ZSOK6Y/EOG4x15MI7Bo4nmDKTF9FHrj7C1PkRT0HLeVjR0OG9bWoIE2sOE/BFbTK0jCUvFop2ct5bjVidh7Y9E9aSv0Wg0BwYK2I/11vSkr9FoNF3RK32NRqM5QIgpCOnKWXuXtrxS/q92PMseXUF7c3C7NnzT5cWVnoXDk44rPcsSVuvBhu9Lc9pJV06yvc6EiFp3NnxPlyQs0y6MsiMbvplU3ETb8HuPx/+7ilyXybB0J1OH51JwcD4Fh5STVpizjQ1/vT/C1pYQFesCVDRvSQiptQQi27XhJ+z3KQip9WS31zb8/ok272g0Gs0BgkJp845Go9EcKGhHrkaj0Rxg6El/L7NhYxX/fuAvnWyhpsuLw+3Fm1PUSTzN7XXj8loFzd0eJ6ZD8PQgnuZ1maQ7TdwOy3ZvCrgdZqKgedf4+7i93rSN4dsraL474mnadr9jfvWPb+IZORZz4EFEcspoUm5q/VEqQlE2Nvmp3BqkYlktmxs2Ut0cpK0lRDAQJtAWtuz2wQjRSKRTQfPu4u/j/iIdf3/goJSO3tFoNJoDBoWO3tFoNJoDBm3T12g0mgMMbd7RaDSaAwTLpr+3R9F39ItJ3+H1MeTYs6zqVk6jI8nK7SA7zYmvO4E008BtV7iyEqqMHTpoUxVIS3bOgk6u2htcb55N9edBAh/VE2jfStAfIeQPE43GiITCCQdtxHbSqmg04aCNRcIJJ6t20Gq6Q6/0NRqN5gBBAXukhMpeQk/6Go1Gk4RC6egdjUajOVCwonf0pL9XOXhQNh//+tS9PQzNPsRLD/11bw9Bs7+ynztyjR2f0vuIyGkiskJEVovI7XtjDBqNRtMd8ZV+Km13EJGLRWSpiMTsYug9ndftfCkiQ0Rkjt3/vIi4UrnvHp/0RcQEHgZOB8YAl4nImD09Do1Go+mJqEqt7SZLgAuAWT2dsIP58tfAQ0qp4UADcHUqN90bK/0jgdVKqbVKqRDwHHDuXhiHRqPRbEMMS4YhlbY7KKWWK6VW7OC0budLsWLBpwIv2ec9CZyXyn33hk2/FNiUtL8ZOKrrSSJyLXCtvRtM83qX7IGx7Snygdq9PYheZH97Htj/nulAep7Bu3PhWkIzHmFDfoqne0RkXtL+o0qpR3fn/l3oab7MAxqVUpGk/tJULrjPOnLtP9yjACIyTynVo82rv6GfZ99nf3sm/Typo5Q6rbeuJSLvAsXdHLpLKfVab91nZ9gbk34FUJa0P9Du02g0mv0KpdRJu3mJnubLOiBbRBz2aj/leXRv2PTnAiNsz7MLuBSYthfGodFoNPs63c6XSikFzAQuss+7Akjpl8Men/Ttb6XvATOA5cALSqmlO3hbb9rI9gX08+z77G/PpJ9nH0NEzheRzcBk4L8iMsPuHyAi02GH8+VtwE0ishrLxv+PlO6r9uPMM41Go9F0Zq8kZ2k0Go1m76AnfY1GozmA2Kcn/f4q1yAij4tItYgsSerLFZF3RGSV/Zpj94uI/NF+xsUiMmHvjbx7RKRMRGaKyDI7bfwHdn+/fCYR8YjIZyKyyH6en9v93aa1i4jb3l9tHy/fqw/QAyJiisjnIvKGvd/fn2e9iHwhIgvjsfD99TO3L7HPTvr9XK7hn0DXWN/bgfeUUiOA9+x9sJ5vhN2uBfZFJbEIcLNSagwwCfiu/W/RX58pCExVSh0KjAdOE5FJ9JzWfjXQYPc/ZJ+3L/IDLGdfnP7+PABTlFLjk2Ly++tnbt9BKbVPNiyP9oyk/TuAO/b2uHZi/OXAkqT9FUCJvV0CrLC3HwEu6+68fbVhhYadvD88E5AGLMDKcqwFHHZ/4vOHFTkx2d522OfJ3h57l+cYiDUJTgXewCrM1m+fxx7beiC/S1+//8zt7bbPrvTpPv04pTTjfZQipVSlvb0VKLK3+9Vz2qaAw4A59ONnsk0hC4Fq4B1gDT2ntSeexz7ehBUity/xe+BHdBR92l6afn94HrAEL98Wkfm2LAv048/cvsI+K8OwP6OUUiLS72JlRcQHvAzcqJRqlqQivf3tmZRSUWC8iGQDrwCj9u6Idh0ROQuoVkrNF5ET9vJwepNjlVIVIlIIvCMiXyYf7G+fuX2FfXmlv7/JNVSJSAmA/Vpt9/eL5xQRJ9aE/7RS6j92d79+JgClVCNWZuNk7LR2+1DymBPPYx/PwkqD31c4BjhHRNZjqTBOBf5A/30eAJRSFfZrNdYX85HsB5+5vc2+POnvb3IN07BSpaFzyvQ04Jt29MEkoCnp5+s+gVhL+n8Ay5VSv0s61C+fSUQK7BU+IuLF8k8sp+e09uTnvAh4X9mG430BpdQdSqmBSqlyrP8n7yulvk4/fR4AEUkXkYz4NnAKlv58v/zM7VPsbafC9hpwBrASy956194ez06M+1mgEghj2RavxrKZvgesAt4Fcu1zBStKaQ3wBTBxb4+/m+c5Fsu+uhhYaLcz+uszAYcAn9vPswS42+4fCnwGrAZeBNx2v8feX20fH7q3n2E7z3YC8EZ/fx577IvstjT+/7+/fub2paZlGDQajeYAYl8272g0Go2ml9GTvkaj0RxA6Elfo9FoDiD0pK/RaDQHEHrS12g0mgMIPelr9joiErWVFJfaypc3i8gufzZF5M6k7XJJUjvVaA509KSv2RfwK0tJ8WCsRKnTgZ/uxvXu3PEpGs2BiZ70NfsUykq5vxb4np1daYrIAyIy19ZJvw5ARE4QkVki8l+xai78TUQMEbkf8Nq/HJ62L2uKyN/tXxJv21m4Gs0BiZ70NfscSqm1gAkUYmUzNymljgCOAL4tIkPsU48Evo9Vb2EYcIFS6nY6fjl83T5vBPCw/UuiEbhwjz2MRrOPoSd9zb7OKViaKgux5JzzsCZxgM+UUmuVpZj5LJZcRHesU0ottLfnY9U60GgOSLS0smafQ0SGAlEsBUUBvq+UmtHlnBOw9ICS6UlTJJi0HQW0eUdzwKJX+pp9ChEpAP4G/FlZwlAzgO/Y0s6IyEhbdRHgSFuF1QAuAT6y+8Px8zUaTWf0Sl+zL+C1zTdOrHq8/wLiEs6PYZljFtgSzzXAefaxucCfgeFYMsKv2P2PAotFZAFwV98PX6PpP2iVTU2/xDbv3KKUOmsvD0Wj6Vdo845Go9EcQOiVvkaj0RxA6JW+RqPRHEDoSV+j0WgOIPSkr9FoNAcQetLXaDSaAwg96Ws0Gs0BxP8DbxbHCOpC0O0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_position_embedding(position_embedding):\n",
    "    plt.pcolormesh(position_embedding[0],cmap = 'RdBu')\n",
    "    plt.xlabel('Depth')\n",
    "    plt.xlim((0,512))\n",
    "    plt.ylabel('Position')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "plot_position_embedding(position_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. padding mask, 2. look ahead \n",
    "\n",
    "# batch_data.shape : [batch_size,seq_len]\n",
    "def create_padding_mask(batch_data):\n",
    "    padding_mask = tf.cast(tf.math.equal(batch_data,0),tf.float32)\n",
    "    # [batch_size,1,1,seq_len]\n",
    "#     return padding_mask[:,tf.newaxis,tf.newaxis,:]\n",
    "    padding_mask = tf.expand_dims(padding_mask,1)\n",
    "    return tf.expand_dims(padding_mask,1)\n",
    "\n",
    "def create_padding_mask2(batch_data):\n",
    "    padding_mask = tf.cast(tf.math.equal(batch_data,0),tf.float32)\n",
    "    # [batch_size,1,1,seq_len]\n",
    "    return padding_mask[:,tf.newaxis,tf.newaxis,:]\n",
    "\n",
    "\n",
    "x = tf.constant([[7,6,0,0,1],\n",
    "                [1,2,3,0,0],\n",
    "                [0,0,0,4,5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention_weights.shape: [3,3]\n",
    "# [[1,2,3],\n",
    "#  [4,5,6],\n",
    "#  [7,8,9]]\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1- tf.linalg.band_part(tf.ones((size,size)),-1,0)\n",
    "    return mask # (seq_len,seq_len)\n",
    "\n",
    "create_look_ahead_mask(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.band_part(tf.ones((3,3)),-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q,k,v,mask):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - q: shape == (...,seq_len_q,depth)\n",
    "    - k: shape == (...,seq_len_k,depth)\n",
    "    - v: shape == (...,seq_len_v,depth_v)\n",
    "    - mask: shape == (...,seq_len_q,seq_len_k)\n",
    "    Returns :\n",
    "    - output: weighted sum\n",
    "    - attention_weights:weights of attention\n",
    "    \"\"\"\n",
    "    # matmul_qk.shape:(...,seq_len_q,seq_len_k)\n",
    "    matmul_qk = tf.matmul(q,k,transpose_b=True)\n",
    "    # print(\"..\",matmul_qk.shape)\n",
    "    dk = tf.cast(tf.shape(k)[-1],tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    if mask is not None:\n",
    "        # 使得在softmax后值趋近于0\n",
    "        scaled_attention_logits += (mask* -1e9)\n",
    "    #attention_weights.shape: (...,seq_len_q,seq_len_len_k)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits,axis = -1)\n",
    "    # output.shape:(...,seq_len_q,depth_v)\n",
    "    output = tf.matmul(attention_weights,v) \n",
    "    return output,attention_weights\n",
    "\n",
    "def print_scaled_dot_produce_attention(q,k,v):\n",
    "    temp_out,temp_att = scaled_dot_product_attention(q,k,v,None)\n",
    "    print(\"Attention weights are:\")\n",
    "    print(temp_att)\n",
    "    print(\"Output is:\")\n",
    "    print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]],dtype = tf.float32)  # (4,3)\n",
    "temp_v = tf.constant([[1,0],\n",
    "                      [10,0],\n",
    "                      [100,5],\n",
    "                      [1000,6]],dtype = tf.float32)  # (4,2)\n",
    "\n",
    "temp_q1 = tf.constant([[0,10,0]],dtype = tf.float32) # (1,3)\n",
    "np.set_printoptions(suppress=True)\n",
    "print_scaled_dot_produce_attention(temp_q1,temp_k,temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60, 512)\n",
      "(1, 8, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    理论上：\n",
    "    x -> Wq0 -> q0\n",
    "    x -> Wk0 -> k0\n",
    "    x -> Wv0 -> v0\n",
    "    实战中：\n",
    "    q -> wq0 -> q0\n",
    "    k -> wk0 -> k0\n",
    "    v -> wv0 -> v0\n",
    "    \n",
    "    实战中技巧：\n",
    "    q -> wq -> Q -> split -> q0,q1,q2...\n",
    "    \"\"\"\n",
    "    def __init__(self,d_model,num_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = self.d_model //self.num_heads\n",
    "        \n",
    "        self.WQ = keras.layers.Dense(self.d_model)\n",
    "        self.WK = keras.layers.Dense(self.d_model)\n",
    "        self.WV = keras.layers.Dense(self.d_model)\n",
    "        self.dense = keras.layers.Dense(self.d_model)\n",
    "        \n",
    "    def split_heads(self,x,batch_size):\n",
    "        # x.shape:(batch_size,seq_len,d_model)\n",
    "        # d_model = num_heads * depth\n",
    "        # x -> (batch_ize,num_heads,seq_len,depth)\n",
    "        x = tf.reshape(x,(batch_size,-1,self.num_heads,self.depth))\n",
    "        return  tf.transpose(x,perm=[0,2,1,3] )\n",
    "    \n",
    "    def call(self,q,k,v,mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.WQ(q) # q.shape: (batch_size,seq_len_q,d_model\n",
    "        k = self.WK(k) # k.shape: (batch_size,seq_len_k,d_model\n",
    "        v = self.WV(v) # v.shape: (batch_size,seq_len_v,d_model\n",
    "        \n",
    "        # q.shape: (batch_size,nm_heads,seq_len_q,depth)\n",
    "        q = self.split_heads(q,batch_size)\n",
    "        # k.shape: (batch_size,nm_heads,seq_len_k,depth)\n",
    "        k = self.split_heads(k,batch_size)\n",
    "        # v.shape: (batch_size,nm_heads,seq_len_v,depth)\n",
    "        v = self.split_heads(v,batch_size)\n",
    "        \n",
    "        # scaled_attention_outputs.shape:(batch_size,num_heads.seq_len_q,depth)\n",
    "        # attention_weights.shape:(batch_size,num_heads,seq_len_q,seq_len_k)\n",
    "        scaled_attention_outputs,attention_weights = scaled_dot_product_attention(q,k,v,mask)\n",
    "        \n",
    "        # scaled_attention_outputs.shape:(batch_size,seq_len_q,num_heads,depth)\n",
    "        scaled_attention_outputs = tf.transpose(scaled_attention_outputs,perm=[0,2,1,3])\n",
    "        concat_attention = tf.reshape(scaled_attention_outputs,(batch_size,-1,self.d_model))\n",
    "        \n",
    "        # output.shape : (batch_size,seq_len_q,d_model)\n",
    "        output = self.dense(concat_attention)\n",
    "        return output,attention_weights\n",
    "\n",
    "temp_mha = MultiHeadAttention(d_model=512,num_heads = 8)\n",
    "y = tf.random.uniform((1,60,256)) # (batch_size,seq_len_q,dim)\n",
    "output,attn = temp_mha(y,y,y,mask = None)\n",
    "print(output.shape)\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feed_forward_network(d_model,dff):\n",
    "    # dff: dim of feed forward network,\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Dense(dff,activation='relu'),\n",
    "        keras.layers.Dense(d_model)\n",
    "    ])\n",
    "sample_ffn = feed_forward_network(512,2048)\n",
    "sample_ffn(tf.random.uniform((64,50,512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    x -> self attention ->add & normalize & dropout\n",
    "      -> feed_forward -> add & normalize & dropout\n",
    "    \"\"\"\n",
    "    def __init__(self,d_model,num_heads,dff,rate=0.1):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model,dff)\n",
    "        self.layer_normal1 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_normal2 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "    def call(self,x,training,encoder_padding_mask):\n",
    "        # x.shape :          (batch_size,seq_len,dim=d_model)\n",
    "        # attn_output.shape: (batch_size,seq_len,d_model)\n",
    "        # out1.shape:        (batch_size,seq_len,d_model)\n",
    "        attn_output,_ = self.mha(x,x,x,encoder_padding_mask)\n",
    "        attn_output = self.dropout1(attn_output,training=training)\n",
    "        out1 = self.layer_normal1(x+attn_output)\n",
    "        # ffn_output.shape: (batch_size,seq_len,d_model)\n",
    "        # out2.shape      : (batch_size,seq_len,d_model)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output,training=training)\n",
    "        out2 = self.layer_normal2(out1+ffn_output)\n",
    "        return out2\n",
    "\n",
    "sample_encoder_layer = EncoderLayer(512,8,2048)\n",
    "sample_input =tf.random.uniform((64,50,512))\n",
    "sample_output = sample_encoder_layer(sample_input,False,None)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 512)\n",
      "(64, 8, 60, 60)\n",
      "(64, 8, 60, 50)\n"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_heads,dff,rate=0.1):\n",
    "        \"\"\"\n",
    "        x -> self attention -> add & normalize & dropout ->out1\n",
    "        out1 ,encoding_outputs -> attention -> add & normalize & dropout -> out2\n",
    "        out2 -> ffn -> add & normalize & dropout -> out3\n",
    "        \"\"\"\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model,num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model,num_heads)\n",
    "        \n",
    "        self.ffn = feed_forward_network(d_model,dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm3 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        self.dropout3 = keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self,x,encoding_outputs,training,decoder_mask,encoder_decoder_padding_mask):\n",
    "        # decoder_mask: look_ahead_mask 和decoder_padding_mask 合并而来\n",
    "        # x.shape: (batch_size,target_seq_len,d_model)\n",
    "        # encoding_outputs.shape: (batch_size,input_seq_len,d_model)\n",
    "        # attn1,out1.shape : (batch_size,target_seq_len,d_model)\n",
    "        attn1,attn_weights1 = self.mha1(x,x,x,decoder_mask)\n",
    "        attn1 = self.dropout1(attn1,training = training)\n",
    "        out1 = self.layer_norm1(attn1 + x)\n",
    "       \n",
    "        # attn2,out2.shape:(batch_size,target_seq_len,d_model)\n",
    "        attn2,attn_weights2 = self.mha2(out1,encoding_outputs,encoding_outputs,encoder_decoder_padding_mask)\n",
    "        attn2 = self.dropout2(attn2,training = training)\n",
    "        out2 = self.layer_norm2(attn2 + out1)\n",
    "        \n",
    "        # ffn_output, out3.shape:(batch_size,target_seq_len,d_model)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output,training=training)\n",
    "        out3 = self.layer_norm3(ffn_output + out2)\n",
    "        \n",
    "        return out3,attn_weights1,attn_weights2\n",
    "\n",
    "sample_decoder_layer = DecoderLayer(512,8,2048)\n",
    "sample_decoder_input = tf.random.uniform((64,60,512))\n",
    "sample_decoder_output,sample_decoder_attn_weights1,sample_decoder_attn_weights2 = sample_decoder_layer(sample_decoder_input,sample_output,False,None,None)\n",
    "print(sample_decoder_output.shape)\n",
    "print(sample_decoder_attn_weights1.shape)\n",
    "print(sample_decoder_attn_weights2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderModel(keras.layers.Layer):\n",
    "    def __init__(self,num_layers,input_vocab_size,max_length,d_model,num_heads,dff,rate = 0.1):\n",
    "        super(EncoderModel,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(input_vocab_size,self.d_model)\n",
    "        # position_embedding.shape:(1,max_length.d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length,self.d_model)\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.encoder_layers = [EncoderLayer(d_model,num_heads,dff,rate) for _ in range(self.num_layers)]\n",
    "    def call(self,x,training,encoder_padding_mask):\n",
    "        # x.shape:(batch_size,input_seq_len)\n",
    "        input_seq_len = tf.shape(x)[1]\n",
    "        tf.debugging.assert_less_equal(input_seq_len,self.max_length,\"input_seq_len should be less or equal to self.max_length\")\n",
    "        \n",
    "        # x.shape:(batch_size,input_seq_len,d_model)\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n",
    "        x += self.position_embedding[:,:input_seq_len,:]\n",
    "        x = self.dropout(x,training = training)\n",
    "        \n",
    "        for i in range (self.num_layers):\n",
    "            x = self.encoder_layers[i](x,training,encoder_padding_mask)\n",
    "            \n",
    "        #x.shape :(batch_size,input_seq_len,d_model)\n",
    "        return x\n",
    "\n",
    "sample_encoder_model = EncoderModel(2,8500,max_length,512,8,2048)\n",
    "sample_encoder_model_input = tf.random.uniform((64,37))\n",
    "sample_encoder_model_output = sample_encoder_model(\n",
    "sample_encoder_model_input,False,encoder_padding_mask =None)\n",
    "print(sample_encoder_model_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35, 512)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n"
     ]
    }
   ],
   "source": [
    "class DecoderModel(keras.layers.Layer):\n",
    "    def __init__(self,num_layers,target_vocab_size,max_length,d_model,num_heads,dff,rate=0.1):\n",
    "        super(DecoderModel,self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(target_vocab_size,d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length,d_model)\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.decoder_layers = [DecoderLayer(d_model,num_heads,dff,rate) for _ in range(self.num_layers)]\n",
    "    \n",
    "    def call(self,x,encoding_outputs,training,decoder_mask,encoder_decoder_padding_mask):\n",
    "        # x .shape : (batch_size,outseq_seq_len)\n",
    "        output_seq_len = tf.shape(x)[1]\n",
    "        tf.debugging.assert_less_equal(output_seq_len,self.max_length,\"output_seq_len should be less or equal to self.max_length\")\n",
    "        \n",
    "        attention_weights = {}\n",
    "        \n",
    "        # x.shape:(batch_size,output_seq_len,d_model)\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n",
    "        x += self.position_embedding[:,:output_seq_len,:]\n",
    "        x = self.dropout(x,training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x,attn1,attn2 = self.decoder_layers[i](x,encoding_outputs,training,decoder_mask,encoder_decoder_padding_mask)\n",
    "            attention_weights['decoder_layer{}_att1'.format(i+1)] = attn1\n",
    "            attention_weights['decoder_layer{}_att2'.format(i+1)] = attn2\n",
    "\n",
    "        # x.shape:(batch_size,output_seq_len,d_model)\n",
    "        return x,attention_weights\n",
    "sample_decoder_model = DecoderModel(2,8000,max_length,512,8,2048)\n",
    "sample_decoder_model_input = tf.random.uniform((64,35))\n",
    "sample_decoder_model_output,sample_decoder_model_att = sample_decoder_model(sample_decoder_model_input,sample_encoder_model_output,training = False,decoder_mask=None,encoder_decoder_padding_mask=None)\n",
    "print(sample_decoder_model_output.shape)\n",
    "for key in sample_decoder_model_att:\n",
    "    print(sample_decoder_model_att[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 31, 8000)\n",
      "decoder_layer1_att1 (64, 8, 31, 31)\n",
      "decoder_layer1_att2 (64, 8, 31, 26)\n",
      "decoder_layer2_att1 (64, 8, 31, 31)\n",
      "decoder_layer2_att2 (64, 8, 31, 26)\n"
     ]
    }
   ],
   "source": [
    "class Transformer(keras.Model):\n",
    "    def __init__(self,num_layers,input_vocab_size,target_vocab_size,max_length,d_model,num_heads,dff,rate=0.1):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.encoder_model = EncoderModel(num_layers,input_vocab_size,max_length,d_model,num_heads,dff,rate)\n",
    "        self.decoder_model = DecoderModel(num_layers,target_vocab_size,max_length,d_model,num_heads,dff,rate)\n",
    "        self.final_layer = keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self,inp,tar,training,encoder_padding_mask,decoder_mask,encoder_decoder_padding_mask):\n",
    "        # encoding_outputs.shape:(batch_size,input_seq_len,d_model)\n",
    "        encoding_outputs = self.encoder_model(inp,training,encoder_padding_mask)\n",
    "        \n",
    "        # decoding_outputs.shape:(b)\n",
    "        decoding_outputs,attention_weights = self.decoder_model(tar,encoding_outputs,training,decoder_mask,encoder_decoder_padding_mask)\n",
    "        \n",
    "        # predictions.shape: (batch_size,output_seq_len,target_vocab_size)\n",
    "        predictions = self.final_layer(decoding_outputs)\n",
    "        \n",
    "        return predictions,attention_weights\n",
    "\n",
    "sample_transformer = Transformer(2,8500,8000,max_length,512,8,2048,rate = 0.1)\n",
    "temp_input = tf.random.uniform((64,26))\n",
    "temp_target = tf.random.uniform((64,31))\n",
    "predictions,attention_weights = sample_transformer(temp_input,temp_target,training = False,\n",
    "                  encoder_padding_mask = None,decoder_mask = None,encoder_decoder_padding_mask=None)\n",
    "print(predictions.shape)\n",
    "for key in attention_weights:\n",
    "    print(key,attention_weights[key].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.initializes model.\n",
    "# 2.define loss,optimizer,lerning_rate schedule\n",
    "# 3.train_step\n",
    "# 4.train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff =512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = pt_tokenizer.vocab_size + 2\n",
    "target_vocab_size = en_tokenizer.vocab_size + 2\n",
    "\n",
    "dropout_rate = 0.1\n",
    "\n",
    "transformer = Transformer(num_layers,input_vocab_size,target_vocab_size,max_length,d_model,num_heads,dff,dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrate = (d_model**-0.5) * min(step_num**(-0.5),step_num*warm_up_steps**(-1.5))\n",
    "class CustomizedSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self,d_model,warmup_steps=4000):\n",
    "        super(CustomizedSchedule,self).__init__()\n",
    "        self.d_model = tf.cast(d_model,tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self,step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** (-1.5))\n",
    "        arg3 = tf.math.rsqrt(self.d_model)\n",
    "        return arg3 * tf.math.minimum(arg1,arg2)\n",
    "learning_rate = CustomizedSchedule(d_model)\n",
    "optimizer = keras.optimizers.Adam(learning_rate,beta_1 = 0.9,beta_2 = 0.98,epsilon = 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train step')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomizedSchedule(d_model)\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000,dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.xlabel(\"Train step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits = True,reduction = 'none')\n",
    "\n",
    "def loss_function(real,pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real,0))\n",
    "    loss_ = loss_object(real,pred)\n",
    "    mask = tf.cast(mask,dtype = loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(inp,tar):\n",
    "    \"\"\"\n",
    "    Encoder:\n",
    "     - encoder_padding_mask (self attention of EncoderLayer)\n",
    "    \n",
    "    Decoder:\n",
    "     - look_ahead_mask (self attention of DecoderLayer)\n",
    "     - encoder_decoder_padding_mask (encoder-decoder attention of DecoderLayer)\n",
    "     - decoder_padding_mask (self attention of DecoderLayer)\n",
    "    \"\"\"\n",
    "    encoder_padding_mask = create_padding_mask(inp)\n",
    "    encoder_decoder_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    decoder_padding_mask = create_padding_mask(tar)\n",
    "    decoder_mask = tf.maximum(decoder_padding_mask,look_ahead_mask)\n",
    "    \n",
    "#     print(encoder_padding_mask.shape)\n",
    "#     print(encoder_decoder_padding_mask.shape)\n",
    "#     print(look_ahead_mask.shape)\n",
    "#     print(decoder_padding_mask.shape)\n",
    "#     print(decoder_mask.shape)\n",
    "    return encoder_padding_mask,decoder_mask,encoder_decoder_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_inp,temp_tar = iter(train_dataset.take(1)).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 40)\n",
      "(64, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 1, 1, 40), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 38, 38), dtype=float32, numpy=\n",
       " array([[[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 1., 1.],\n",
       "          [0., 0., 0., ..., 0., 0., 1.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 1, 40), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(temp_inp.shape)\n",
    "print(temp_tar.shape)\n",
    "create_mask(temp_inp,temp_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.2933 Accuracy 0.0000\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 9 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 9 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 10 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 10 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 13 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 13 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function train_step at 0x00000204CB605B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 100 Loss 4.1491 Accuracy 0.0142\n",
      "Epoch 1 Batch 200 Loss 4.0583 Accuracy 0.0208\n",
      "Epoch 1 Batch 300 Loss 3.9170 Accuracy 0.0253\n",
      "Epoch 1 Batch 400 Loss 3.7436 Accuracy 0.0315\n",
      "Epoch 1 Batch 500 Loss 3.5944 Accuracy 0.0372\n",
      "Epoch 1 Batch 600 Loss 3.4740 Accuracy 0.0443\n",
      "Epoch 1 Batch 700 Loss 3.3653 Accuracy 0.0514\n",
      "Epoch1 Loss3.3634 Accuracy0.0515\n",
      "Time take for 1 epoch:789.3295850753784 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.4140 Accuracy 0.0991\n",
      "Epoch 2 Batch 100 Loss 2.5369 Accuracy 0.1061\n",
      "Epoch 2 Batch 200 Loss 2.5053 Accuracy 0.1110\n",
      "Epoch 2 Batch 300 Loss 2.4760 Accuracy 0.1145\n",
      "Epoch 2 Batch 400 Loss 2.4494 Accuracy 0.1178\n",
      "Epoch 2 Batch 500 Loss 2.4171 Accuracy 0.1208\n",
      "Epoch 2 Batch 600 Loss 2.3884 Accuracy 0.1232\n",
      "Epoch 2 Batch 700 Loss 2.3662 Accuracy 0.1257\n",
      "Epoch2 Loss2.3662 Accuracy0.1258\n",
      "Time take for 1 epoch:683.194947719574 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.9389 Accuracy 0.1426\n",
      "Epoch 3 Batch 100 Loss 2.1667 Accuracy 0.1445\n",
      "Epoch 3 Batch 200 Loss 2.1565 Accuracy 0.1450\n",
      "Epoch 3 Batch 300 Loss 2.1509 Accuracy 0.1464\n",
      "Epoch 3 Batch 400 Loss 2.1330 Accuracy 0.1477\n",
      "Epoch 3 Batch 500 Loss 2.1174 Accuracy 0.1490\n",
      "Epoch 3 Batch 600 Loss 2.1016 Accuracy 0.1507\n",
      "Epoch 3 Batch 700 Loss 2.0916 Accuracy 0.1524\n",
      "Epoch3 Loss2.0919 Accuracy0.1524\n",
      "Time take for 1 epoch:781.2729210853577 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.9296 Accuracy 0.1591\n",
      "Epoch 4 Batch 100 Loss 1.9269 Accuracy 0.1685\n",
      "Epoch 4 Batch 200 Loss 1.9203 Accuracy 0.1712\n",
      "Epoch 4 Batch 300 Loss 1.9137 Accuracy 0.1732\n",
      "Epoch 4 Batch 400 Loss 1.8981 Accuracy 0.1751\n",
      "Epoch 4 Batch 500 Loss 1.8813 Accuracy 0.1770\n",
      "Epoch 4 Batch 600 Loss 1.8708 Accuracy 0.1793\n",
      "Epoch 4 Batch 700 Loss 1.8561 Accuracy 0.1810\n",
      "Epoch4 Loss1.8558 Accuracy0.1811\n",
      "Time take for 1 epoch:814.0205121040344 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.5256 Accuracy 0.1871\n",
      "Epoch 5 Batch 100 Loss 1.6796 Accuracy 0.1978\n",
      "Epoch 5 Batch 200 Loss 1.6657 Accuracy 0.2003\n",
      "Epoch 5 Batch 300 Loss 1.6654 Accuracy 0.2021\n",
      "Epoch 5 Batch 400 Loss 1.6578 Accuracy 0.2033\n",
      "Epoch 5 Batch 500 Loss 1.6522 Accuracy 0.2044\n",
      "Epoch 5 Batch 600 Loss 1.6468 Accuracy 0.2059\n",
      "Epoch 5 Batch 700 Loss 1.6371 Accuracy 0.2070\n",
      "Epoch5 Loss1.6371 Accuracy0.2070\n",
      "Time take for 1 epoch:865.3488719463348 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.5774 Accuracy 0.2217\n",
      "Epoch 6 Batch 100 Loss 1.4883 Accuracy 0.2216\n",
      "Epoch 6 Batch 200 Loss 1.4859 Accuracy 0.2218\n",
      "Epoch 6 Batch 300 Loss 1.4804 Accuracy 0.2232\n",
      "Epoch 6 Batch 400 Loss 1.4791 Accuracy 0.2250\n",
      "Epoch 6 Batch 500 Loss 1.4719 Accuracy 0.2256\n",
      "Epoch 6 Batch 600 Loss 1.4621 Accuracy 0.2263\n",
      "Epoch 6 Batch 700 Loss 1.4542 Accuracy 0.2273\n",
      "Epoch6 Loss1.4538 Accuracy0.2273\n",
      "Time take for 1 epoch:952.4843163490295 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.3309 Accuracy 0.2711\n",
      "Epoch 7 Batch 100 Loss 1.2889 Accuracy 0.2450\n",
      "Epoch 7 Batch 200 Loss 1.2921 Accuracy 0.2441\n",
      "Epoch 7 Batch 300 Loss 1.2889 Accuracy 0.2452\n",
      "Epoch 7 Batch 400 Loss 1.2869 Accuracy 0.2463\n",
      "Epoch 7 Batch 500 Loss 1.2764 Accuracy 0.2471\n",
      "Epoch 7 Batch 600 Loss 1.2728 Accuracy 0.2480\n",
      "Epoch 7 Batch 700 Loss 1.2657 Accuracy 0.2487\n",
      "Epoch7 Loss1.2657 Accuracy0.2487\n",
      "Time take for 1 epoch:939.5366396903992 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.2105 Accuracy 0.2991\n",
      "Epoch 8 Batch 100 Loss 1.1181 Accuracy 0.2664\n",
      "Epoch 8 Batch 200 Loss 1.1182 Accuracy 0.2655\n",
      "Epoch 8 Batch 300 Loss 1.1172 Accuracy 0.2651\n",
      "Epoch 8 Batch 400 Loss 1.1166 Accuracy 0.2658\n",
      "Epoch 8 Batch 500 Loss 1.1171 Accuracy 0.2665\n",
      "Epoch 8 Batch 600 Loss 1.1185 Accuracy 0.2670\n",
      "Epoch 8 Batch 700 Loss 1.1154 Accuracy 0.2672\n",
      "Epoch8 Loss1.1155 Accuracy0.2673\n",
      "Time take for 1 epoch:984.4971215724945 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.9434 Accuracy 0.3173\n",
      "Epoch 9 Batch 100 Loss 0.9828 Accuracy 0.2802\n",
      "Epoch 9 Batch 200 Loss 0.9932 Accuracy 0.2788\n",
      "Epoch 9 Batch 300 Loss 0.9949 Accuracy 0.2788\n",
      "Epoch 9 Batch 400 Loss 0.9975 Accuracy 0.2799\n",
      "Epoch 9 Batch 500 Loss 0.9988 Accuracy 0.2804\n",
      "Epoch 9 Batch 600 Loss 1.0012 Accuracy 0.2807\n",
      "Epoch 9 Batch 700 Loss 1.0054 Accuracy 0.2804\n",
      "Epoch9 Loss1.0057 Accuracy0.2804\n",
      "Time take for 1 epoch:1015.5219452381134 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.8276 Accuracy 0.3011\n",
      "Epoch 10 Batch 100 Loss 0.8985 Accuracy 0.2911\n",
      "Epoch 10 Batch 200 Loss 0.9055 Accuracy 0.2914\n",
      "Epoch 10 Batch 300 Loss 0.9072 Accuracy 0.2912\n",
      "Epoch 10 Batch 400 Loss 0.9113 Accuracy 0.2912\n",
      "Epoch 10 Batch 500 Loss 0.9153 Accuracy 0.2913\n",
      "Epoch 10 Batch 600 Loss 0.9208 Accuracy 0.2915\n",
      "Epoch 10 Batch 700 Loss 0.9234 Accuracy 0.2911\n",
      "Epoch10 Loss0.9231 Accuracy0.2911\n",
      "Time take for 1 epoch:1030.3166749477386 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.8558 Accuracy 0.3062\n",
      "Epoch 11 Batch 100 Loss 0.8276 Accuracy 0.3030\n",
      "Epoch 11 Batch 200 Loss 0.8368 Accuracy 0.3016\n",
      "Epoch 11 Batch 300 Loss 0.8420 Accuracy 0.3008\n",
      "Epoch 11 Batch 400 Loss 0.8449 Accuracy 0.3007\n",
      "Epoch 11 Batch 500 Loss 0.8516 Accuracy 0.3003\n",
      "Epoch 11 Batch 600 Loss 0.8541 Accuracy 0.3001\n",
      "Epoch 11 Batch 700 Loss 0.8577 Accuracy 0.2996\n",
      "Epoch11 Loss0.8577 Accuracy0.2996\n",
      "Time take for 1 epoch:1069.866061449051 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.7076 Accuracy 0.3007\n",
      "Epoch 12 Batch 100 Loss 0.7826 Accuracy 0.3130\n",
      "Epoch 12 Batch 200 Loss 0.7852 Accuracy 0.3099\n",
      "Epoch 12 Batch 300 Loss 0.7907 Accuracy 0.3092\n",
      "Epoch 12 Batch 400 Loss 0.7939 Accuracy 0.3085\n",
      "Epoch 12 Batch 500 Loss 0.7998 Accuracy 0.3081\n",
      "Epoch 12 Batch 600 Loss 0.8043 Accuracy 0.3077\n",
      "Epoch 12 Batch 700 Loss 0.8051 Accuracy 0.3069\n",
      "Epoch12 Loss0.8050 Accuracy0.3069\n",
      "Time take for 1 epoch:1019.3295080661774 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.7883 Accuracy 0.3438\n",
      "Epoch 13 Batch 100 Loss 0.7278 Accuracy 0.3156\n",
      "Epoch 13 Batch 200 Loss 0.7288 Accuracy 0.3138\n",
      "Epoch 13 Batch 300 Loss 0.7383 Accuracy 0.3139\n",
      "Epoch 13 Batch 400 Loss 0.7425 Accuracy 0.3135\n",
      "Epoch 13 Batch 500 Loss 0.7486 Accuracy 0.3140\n",
      "Epoch 13 Batch 600 Loss 0.7544 Accuracy 0.3136\n",
      "Epoch 13 Batch 700 Loss 0.7571 Accuracy 0.3132\n",
      "Epoch13 Loss0.7575 Accuracy0.3133\n",
      "Time take for 1 epoch:1030.6490032672882 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.6768 Accuracy 0.3150\n",
      "Epoch 14 Batch 100 Loss 0.6748 Accuracy 0.3217\n",
      "Epoch 14 Batch 200 Loss 0.6820 Accuracy 0.3211\n",
      "Epoch 14 Batch 300 Loss 0.6917 Accuracy 0.3209\n",
      "Epoch 14 Batch 400 Loss 0.7015 Accuracy 0.3204\n",
      "Epoch 14 Batch 500 Loss 0.7062 Accuracy 0.3203\n",
      "Epoch 14 Batch 600 Loss 0.7113 Accuracy 0.3199\n",
      "Epoch 14 Batch 700 Loss 0.7179 Accuracy 0.3197\n",
      "Epoch14 Loss0.7181 Accuracy0.3196\n",
      "Time take for 1 epoch:1084.0282969474792 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.5729 Accuracy 0.3332\n",
      "Epoch 15 Batch 100 Loss 0.6508 Accuracy 0.3334\n",
      "Epoch 15 Batch 200 Loss 0.6579 Accuracy 0.3288\n",
      "Epoch 15 Batch 300 Loss 0.6602 Accuracy 0.3272\n",
      "Epoch 15 Batch 400 Loss 0.6645 Accuracy 0.3266\n",
      "Epoch 15 Batch 500 Loss 0.6695 Accuracy 0.3252\n",
      "Epoch 15 Batch 600 Loss 0.6769 Accuracy 0.3250\n",
      "Epoch 15 Batch 700 Loss 0.6820 Accuracy 0.3244\n",
      "Epoch15 Loss0.6821 Accuracy0.3244\n",
      "Time take for 1 epoch:1115.640896320343 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.5951 Accuracy 0.3534\n",
      "Epoch 16 Batch 100 Loss 0.6225 Accuracy 0.3366\n",
      "Epoch 16 Batch 200 Loss 0.6267 Accuracy 0.3337\n",
      "Epoch 16 Batch 300 Loss 0.6329 Accuracy 0.3329\n",
      "Epoch 16 Batch 400 Loss 0.6365 Accuracy 0.3308\n",
      "Epoch 16 Batch 500 Loss 0.6432 Accuracy 0.3306\n",
      "Epoch 16 Batch 600 Loss 0.6468 Accuracy 0.3297\n",
      "Epoch 16 Batch 700 Loss 0.6505 Accuracy 0.3293\n",
      "Epoch16 Loss0.6506 Accuracy0.3293\n",
      "Time take for 1 epoch:1122.190731048584 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.4979 Accuracy 0.3145\n",
      "Epoch 17 Batch 100 Loss 0.5856 Accuracy 0.3409\n",
      "Epoch 17 Batch 200 Loss 0.5959 Accuracy 0.3382\n",
      "Epoch 17 Batch 300 Loss 0.6025 Accuracy 0.3361\n",
      "Epoch 17 Batch 400 Loss 0.6085 Accuracy 0.3353\n",
      "Epoch 17 Batch 500 Loss 0.6135 Accuracy 0.3350\n",
      "Epoch 17 Batch 600 Loss 0.6185 Accuracy 0.3345\n",
      "Epoch 17 Batch 700 Loss 0.6236 Accuracy 0.3338\n",
      "Epoch17 Loss0.6237 Accuracy0.3339\n",
      "Time take for 1 epoch:1095.1419968605042 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.6180 Accuracy 0.3564\n",
      "Epoch 18 Batch 100 Loss 0.5602 Accuracy 0.3439\n",
      "Epoch 18 Batch 200 Loss 0.5721 Accuracy 0.3428\n",
      "Epoch 18 Batch 300 Loss 0.5811 Accuracy 0.3415\n",
      "Epoch 18 Batch 400 Loss 0.5857 Accuracy 0.3406\n",
      "Epoch 18 Batch 500 Loss 0.5894 Accuracy 0.3396\n",
      "Epoch 18 Batch 600 Loss 0.5944 Accuracy 0.3385\n",
      "Epoch 18 Batch 700 Loss 0.5987 Accuracy 0.3378\n",
      "Epoch18 Loss0.5986 Accuracy0.3378\n",
      "Time take for 1 epoch:1134.6649692058563 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.5247 Accuracy 0.3365\n",
      "Epoch 19 Batch 100 Loss 0.5365 Accuracy 0.3456\n",
      "Epoch 19 Batch 200 Loss 0.5472 Accuracy 0.3437\n",
      "Epoch 19 Batch 300 Loss 0.5545 Accuracy 0.3448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 400 Loss 0.5578 Accuracy 0.3432\n",
      "Epoch 19 Batch 500 Loss 0.5622 Accuracy 0.3421\n",
      "Epoch 19 Batch 600 Loss 0.5682 Accuracy 0.3416\n",
      "Epoch 19 Batch 700 Loss 0.5750 Accuracy 0.3411\n",
      "Epoch19 Loss0.5748 Accuracy0.3411\n",
      "Time take for 1 epoch:1105.7110526561737 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.5014 Accuracy 0.3233\n",
      "Epoch 20 Batch 100 Loss 0.5196 Accuracy 0.3485\n",
      "Epoch 20 Batch 200 Loss 0.5238 Accuracy 0.3456\n",
      "Epoch 20 Batch 300 Loss 0.5309 Accuracy 0.3450\n",
      "Epoch 20 Batch 400 Loss 0.5368 Accuracy 0.3456\n",
      "Epoch 20 Batch 500 Loss 0.5417 Accuracy 0.3456\n",
      "Epoch 20 Batch 600 Loss 0.5486 Accuracy 0.3447\n",
      "Epoch 20 Batch 700 Loss 0.5541 Accuracy 0.3442\n",
      "Epoch20 Loss0.5544 Accuracy0.3442\n",
      "Time take for 1 epoch:1125.6907103061676 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "train_loss = keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "@tf.function\n",
    "def train_step(inp,tar):\n",
    "    tar_inp = tar[:,:-1]\n",
    "    tar_real = tar[:,1:]\n",
    "    \n",
    "    encoder_padding_mask,decoder_mask,encoder_decoder_padding_mask = create_mask(inp,tar_inp)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions,_ = transformer(inp,tar_inp,True,encoder_padding_mask,decoder_mask,encoder_decoder_padding_mask)\n",
    "        loss = loss_function(tar_real,predictions)\n",
    "    gradients = tape.gradient(loss,transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,transformer.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real,predictions)\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (batch,(inp,tar)) in enumerate(train_dataset):\n",
    "        train_step(inp,tar)\n",
    "        if batch % 100 ==0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch+1,batch,train_loss.result(),train_accuracy.result()))\n",
    "    print('Epoch{} Loss{:.4f} Accuracy{:.4f}'.format(epoch+1,train_loss.result(),train_accuracy.result()))\n",
    "    print('Time take for 1 epoch:{} secs\\n'.format(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "eg: A B C D -> E F G H.\n",
    "Train: A B C D , E F G -> F G H\n",
    "Eval: A B C D -> E \n",
    "      A B C D ,E -> F\n",
    "      A B C D ,E F -> G \n",
    "\"\"\"\n",
    "def evaluate(inp_sentence):\n",
    "    input_id_sentence = [pt_tokenizer.vocab_size] + pt_tokenizer.encode(inp_sentence) + [pt_tokenizer.vocab_size+1]\n",
    "    # encoder_input.shape: (1,input_sentence_length)\n",
    "    encoder_input = tf.expand_dims(input_id_sentence,0)\n",
    "    # decoder_input.shape: (1,1)\n",
    "    decoder_input = tf.expand_dims([en_tokenizer.vocab_size],0)\n",
    "    for i in range(max_length):\n",
    "        encoder_padding_mask,decoder_mask,encoder_decoder_padding_mask = create_mask(encoder_input,decoder_input)\n",
    "        # predictions.shape:(batch_size,ouput_target_len,target_vocab_size)\n",
    "        predictions,attention_weights = transformer(encoder_input,decoder_input,False,encoder_padding_mask,decoder_mask,encoder_decoder_padding_mask)\n",
    "        \n",
    "        # predictions.shape:(batch_size,target_vocab_size)\n",
    "        predictions = predictions[:,-1,:]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions,axis = -1),tf.int32)\n",
    "        if tf.equal(predicted_id,en_tokenizer.vocab_size+1):\n",
    "            return tf.squeeze(decoder_input,axis=0),attention_weights\n",
    "        decoder_input = tf.concat([decoder_input,[predicted_id]],axis=-1)\n",
    "    return tf.squeeze(decoder_input,axis=0),attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encoder_decoder_attention(attention,input_sentence,result,layer_name):\n",
    "    fig = plt.figure(figsize = (16,8))\n",
    "    input_id_sentence = pt_tokenizer.encode(input_sentence)\n",
    "    # attention.shape: (1，num_heads,tar_len,input_len)\n",
    "    attention = tf.squeeze(attention[layer_name],axis = 0)\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2,4,head+1)\n",
    "        ax.matshow(attention[head][:-1,:])\n",
    "        fontdict = {'fontsize':10}\n",
    "        ax.set_xticks(range(len(input_id_sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "        \n",
    "        ax.set_ylim(len(result)-1.5,-0.5)\n",
    "        \n",
    "        ax.set_xticklabels(\n",
    "        ['<start>']+[pt_tokenizer.decode([i])for i in input_id_sentence] +['<end>'],\n",
    "        fontdict = fontdict,rotation = 90)\n",
    "        ax.set_yticklabels([en_tokenizer.decode([i])for i in result if i<en_tokenizer.vocab_size],\n",
    "                          fontdict = fontdict)\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence,layer_name=''):\n",
    "    result,attention_weights = evaluate(input_sentence)\n",
    "    predicted_sentence = en_tokenizer.decode([ i for i in result if i <en_tokenizer.vocab_size])\n",
    "    print(\"Input:{}\".format(input_sentence))\n",
    "    print(\"Predicted translation:{}\".format(predicted_sentence))\n",
    "    if layer_name:\n",
    "        plot_encoder_decoder_attention(attention_weights,input_sentence,result,layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:está muito frio aqui\n",
      "Predicted translation:it 's very cold here .\n"
     ]
    }
   ],
   "source": [
    "translate('está muito frio aqui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:está muito frio aqui\n",
      "Predicted translation:it 's very cold here .\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (8), usually from a call to set_ticks, does not match the number of ticklabels (7).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-0497666b4945>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'está muito frio aqui'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'decoder_layer4_att2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-4f22594f3284>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(input_sentence, layer_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted translation:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mplot_encoder_decoder_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-5112c0a2a78f>\u001b[0m in \u001b[0;36mplot_encoder_decoder_attention\u001b[1;34m(attention, input_sentence, result, layer_name)\u001b[0m\n\u001b[0;32m     17\u001b[0m         fontdict = fontdict,rotation = 90)\n\u001b[0;32m     18\u001b[0m         ax.set_yticklabels([en_tokenizer.decode([i])for i in result if i<en_tokenizer.vocab_size],\n\u001b[1;32m---> 19\u001b[1;33m                           fontdict = fontdict)\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Head {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1793\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_keyword_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"3.2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"minor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1713\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m                 raise ValueError(\n\u001b[1;32m-> 1715\u001b[1;33m                     \u001b[1;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1716\u001b[0m                     \u001b[1;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1717\u001b[0m                     \u001b[1;34m\" set_ticks, does not match\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (8), usually from a call to set_ticks, does not match the number of ticklabels (7)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('está muito frio aqui',layer_name = 'decoder_layer4_att2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\DeepLearningDemo'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
